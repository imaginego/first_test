from collections import defaultdict
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn import preprocessing
import re

class BaseFeatureExtraction(object):
	def __init__(self):
		self.method_info = ''
	def print_info(self):
		print(self.method_info)
	def get_info(self):
		return self.method_info
	def transform(self,X_train,X_test):
		return X_train,X_test

class CategoricalFeature(BaseFeatureExtraction):
    def __init__(self):
        super(CategoricalFeature, self ).__init__()
    
    def label_encoding(self,df1,df2):
        categorical = ['building_id', 'manager_id', 'display_address']
        fea_list = categorical
        for f in categorical:
            encoder = preprocessing.LabelEncoder()
            encoder.fit(list(df1[f]) + list(df2[f])) 
            df1[f] = encoder.transform(df1[f].ravel())
            df2[f] = encoder.transform(df2[f].ravel())
            mm = max(max(df1[f]),max(df2[f]))
            mm = mm*1.0
            df1[f] = df1[f]/mm
            df2[f] = df2[f]/mm
        return df1,df2,fea_list
    
    def objects_with_only_one_record(self,df,feature_name):
            #import pdb;pdb.set_trace()
        temp = df.groupby(feature_name, as_index = False).count()
        return temp[temp['source'] == 1]

    
    def prepare_categorical(self,df1_,df2_):
        df1 = df1_.copy()
        df2 = df2_.copy()
        df1['source'] = 1
        df2['source'] = 2
        df = df1.append(df2)
        df = df.reset_index(drop=True)
    
    #some of the building id is zero, whereas other rows with same street address have nonzero building_id
    #nonzero = df[(df['building_id']!='0')&(df['street_address']!='')&(df['street_address'].notnull())]
    #id_addr = nonzero.groupby('street_address')['building_id'].first().reset_index()
    #del df['building_id']
    #df = pd.merge(df,id_addr,on='street_address',how='left')
    #df['building_id'] = df['building_id'].fillna('0')
    
    #assign those categorical data that only appear once to the same value
        
        #import pdb;pdb.set_trace()
        managers_with_one_lot = self.objects_with_only_one_record(df,'manager_id')
        buildings_with_one_lot = self.objects_with_only_one_record(df,'building_id')
        addresses_with_one_lot = self.objects_with_only_one_record(df,'display_address')

        df.loc[df['manager_id'].isin(managers_with_one_lot['manager_id'].ravel()), 
          'manager_id'] = "once"
        df.loc[df['building_id'].isin(buildings_with_one_lot['building_id'].ravel()), 
          'building_id'] = "once"
        df.loc[df['display_address'].isin(addresses_with_one_lot['display_address'].ravel()), 
          'display_address'] = "once"
                
        df1 = df[df['source']==1].copy()
        df2 = df[df['source']==2].copy()
        del df1['source']
        del df2['source']
        del df
    
        return df1,df2
    
class Categorical_cv(CategoricalFeature):
    def __init__(self,nfold,k=3.0,f=1.0,r_k=0.01,g=1.0):
        super(Categorical_cv,self).__init__()
        self.nfold = nfold     
        self.k = k
        self.f = f
        self.r_k = r_k
        self.g = g
        self.method_info = "Categorical feature generated by CV"
        
    def cat2num(self,df_tr_,df_te_,cat_var,target):
        #example: cat_var = 'building_id', target='medium'
        dftrain = df_tr_.copy()
        dftest = df_te_.copy()
    
        global_avg = dftrain[target].sum()*1.0/len(dftrain)
        gp = dftrain.groupby(cat_var)
        cat_avg = gp[target].agg({'avg':np.mean,
                             'cnt':lambda x:len(x)})
        cat_avg = cat_avg.reset_index()
        cat_avg['beta'] = cat_avg['cnt'].map(lambda x:1./(self.g+np.exp((x-self.k)/self.f)) if x<200 else 0.)
    
        cat_avg['cat2num'] = cat_avg['avg']*(1-cat_avg['beta']) + global_avg*cat_avg['beta']
        dftest = pd.merge(dftest,cat_avg[[cat_var,'cat2num']],on=cat_var,how='left')
        dftest['cat2num'] = dftest['cat2num'].fillna(global_avg)
    
        return dftest['cat2num'].as_matrix()
    
    def categorical_average(self,Xtrain_,Xtest_,variable,target):       
        X_train = Xtrain_.copy()
        X_test = Xtest_.copy()
    
        k_fold = StratifiedKFold(self.nfold,shuffle=True,random_state=222)
        fea_name = variable + '_' + target
        fea_train = np.zeros(len(X_train))
            
        for train_inx,cv_inx in k_fold.split(np.zeros((len(X_train),2)),X_train['interest_level'].ravel()):
            fea_train[cv_inx] = self.cat2num(X_train.iloc[train_inx,:],X_train.iloc[cv_inx,:],variable,target)
    
        X_train[fea_name] = fea_train
        X_test.loc[:,fea_name] = self.cat2num(X_train,X_test,variable,target)
        return X_train,X_test,fea_name
    
    def transform(self,xtrain_,xtest_):
        Xtrain,Xtest = self.prepare_categorical(xtrain_,xtest_)
    
        #categorical = ['building_id', 'manager_id', 'display_address']
        #fea_list = categorical
        #for f in categorical:
        #    encoder = preprocessing.LabelEncoder()
        #    encoder.fit(list(Xtrain[f]) + list(Xtest[f])) 
        #    Xtrain[f] = encoder.transform(Xtrain[f].ravel())
        #    Xtest[f] = encoder.transform(Xtest[f].ravel())
            
        Xtrain,Xtest,fea_list = self.label_encoding(Xtrain,Xtest)
        
        Xtrain['low'] = 0
        Xtrain.loc[Xtrain['interest_level'] == 0, 'low'] = 1
        Xtrain['medium'] = 0
        Xtrain.loc[Xtrain['interest_level'] == 1, 'medium'] = 1
        Xtrain['high'] = 0
        Xtrain.loc[Xtrain['interest_level'] == 2, 'high'] = 1
    
        for col in ["building_id", "manager_id"]:        
            Xtrain,Xtest,fea1 = self.categorical_average(Xtrain,Xtest,col, "medium")
            Xtrain,Xtest,fea2 = self.categorical_average(Xtrain,Xtest,col, "high")
            fea_list += [fea1,fea2]
    
    
        return Xtrain,Xtest,fea_list    

class CategoricalLit(CategoricalFeature):
    def __init__(self,nfold,k=5.0,f=1.0,r_k=0.01,g=1.0):
        self.k = k
        self.f = f
        self.r_k = r_k
        self.g = g
        self.nfold = nfold
        self.global_avg = None
        super(CategoricalLit,self).__init__()
        self.method_info = "Categorical feature by Branden, it is lit"
        
    def cat2num(self,df_tr_,df_te_,cat_var,target):
        #example: cat_var = 'building_id', target='medium'
        dftrain = df_tr_.copy()
        dftest = df_te_.copy()
    
        
        gp = dftrain.groupby(cat_var)
        cat_avg = gp[target].agg({'avg':np.mean,
                             'cnt':lambda x:len(x)})
        cat_avg = cat_avg.reset_index()
        cat_avg['beta'] = cat_avg['cnt'].map(lambda x:1./(self.g+np.exp((x-self.k)/self.f)) if x<200 else 0.)
    
        cat_avg['cat2num'] = cat_avg['avg']*(1-cat_avg['beta']) + self.global_avg*cat_avg['beta']
        
        dftest = pd.merge(dftest,cat_avg[[cat_var,'cat2num']],on=cat_var,how='left')
        dftest['cat2num'] = dftest['cat2num'].fillna(self.global_avg)
        if self.r_k: 
            ratio = np.random.uniform(1 - self.r_k, 1 + self.r_k, len(dftest))
        else:
            ratio = 1
        return dftest['cat2num'].as_matrix()*ratio
    
    def categorical_average(self,Xtrain_,Xtest_,variable,target):       
        X_train = Xtrain_.copy()
        X_test = Xtest_.copy()
    
        self.global_avg = X_train[target].sum()*1.0/len(X_train)
        
        k_fold = StratifiedKFold(self.nfold,shuffle=True,random_state=222)
        fea_name = variable + '_' + target +'_lit'
        fea_train = np.zeros(len(X_train))
    
        for train_inx,cv_inx in k_fold.split(np.zeros((len(X_train),2)),X_train['interest_level'].ravel()):
            fea_train[cv_inx] = self.cat2num(X_train.iloc[train_inx,:],X_train.iloc[cv_inx,:],variable,target)
    
        X_train[fea_name] = fea_train
        X_test.loc[:,fea_name] = self.cat2num(X_train,X_test,variable,target)
        return X_train,X_test,fea_name
    
    def transform(self,xtrain_,xtest_):
        Xtrain,Xtest = self.prepare_categorical(xtrain_,xtest_)
    
        #categorical = ['building_id', 'manager_id', 'display_address']
        #fea_list = categorical
        #for f in categorical:
        #    encoder = preprocessing.LabelEncoder()
        #    encoder.fit(list(Xtrain[f]) + list(Xtest[f])) 
        #    Xtrain[f] = encoder.transform(Xtrain[f].ravel())
        #    Xtest[f] = encoder.transform(Xtest[f].ravel())
    
        Xtrain,Xtest,fea_list = self.label_encoding(Xtrain,Xtest)
        Xtrain['low'] = 0
        Xtrain.loc[Xtrain['interest_level'] == 0, 'low'] = 1
        Xtrain['medium'] = 0
        Xtrain.loc[Xtrain['interest_level'] == 1, 'medium'] = 1
        Xtrain['high'] = 0
        Xtrain.loc[Xtrain['interest_level'] == 2, 'high'] = 1
    
        for col in ["building_id", "manager_id"]:        
            Xtrain,Xtest,fea1 = self.categorical_average(Xtrain,Xtest,col, "medium")
            Xtrain,Xtest,fea2 = self.categorical_average(Xtrain,Xtest,col, "high")
            fea_list += [fea1,fea2]
    
    
        return Xtrain,Xtest,fea_list    

class TextFeature(BaseFeatureExtraction):
    def __init__(self,nTop=300,combine=True):
        super(TextFeature,self).__init__()
        self.nTop = nTop
        self.combine = combine		
        self.method_info = "Keyword features extract from the column features"
        
    def transform(self,df_train,df_test):
        #df1_ is training set
        #df2_ is test set

        df1 = df_train.copy() # Maybe ther eis better way to avoid SettingWithCopyWarning 
        df2 = df_test.copy()
        df1['source'] = 1
        df2['source'] = 2
        df = df1.append(df2)
        df = df.reset_index(drop=True)
        

        df['description'] = df['description'].map(lambda x:x.lower())
        #---------------------------
        #original length of the first feature, meant to capture those features typed in with wrong 
        # format -- all features are cramed into one phrase
        df['len_feature0'] = df['features'].map(lambda x:0 if len(x)==0 else len(x[0])) 
        #-----------------------------
    
        def fea_clean(x): 
            if len(x) == 1:
                tmp = x[0].strip('*').split('*')
                if len(tmp) ==1:
                    tmp = tmp[0].split(u'\u2022')
                x = tmp
            ret = [tt.encode('utf-8').decode('unicode_escape').encode('ascii','ignore').lower().strip() for tt in x]
            return ret
        df['features'] = df['features'].map(fea_clean)
    
    
        all_fea = defaultdict(int)
        for _,row in df.iterrows():
            for xx in row['features']:
                all_fea[xx] += 1
        sorted_fea = sorted(all_fea.iteritems(),key=lambda (k,v): v,reverse=True)
    
        combined_fea = {'laundry in unit':['laundry in unit','in-unit washer/dryer','washer & dryer',
                                        'washer/dryer','washer/dryer in unit'],
                   'laundry in building':['laundry in building','laundry room',
                                           'washer/dryer in building','on-site laundry'],
                   'gym/fitness':['gym/fitness','fitness center','gym','gym in building'],
                   'pre-war':['pre-war','prewar'],
                    'live-in superintendent':['live-in superintendent','live-in super','live in super'],
                    'hardwood floors':['hardwood floors','hardwood','hardwood floor','hardwood flooring'],
                    'high ceiling':['high ceiling','high ceilings'],
                    'full-time doorman':['full-time doorman','ft doorman','24/7 doorman','24 hour doorman',
                                        '24-hour doorman','24hr doorman','full time doorman','24 hr doorman']
                   #'garage':['garage','parking']
                   }
    
        fea_list = set([v[0] for v in sorted_fea[:self.nTop]])
        for k,v in combined_fea.iteritems():
            fea_list = fea_list.union(set(v))
        for fea in fea_list:
            df[fea] = 0
        #import pdb;pdb.set_trace()
        for inx,row in df.iterrows():
            notlist = []
            if len(row['features']) == 0:
                continue
            for ff in row['features']:
                if ff in fea_list:
                    df.set_value(inx,ff,1)
                else:
                    notlist.append(ff)
        #df.set_value(inx,'description',row['description'] + ' '.join(notlist))
        #print 'fea_list length is {}'.format(len(fea_list))
        fea_list = set(fea_list)
        if self.combine:        
            for k,v in combined_fea.iteritems():
                df[k] = df[v[0]]
            #print k,v
                for ii in range(1,len(v)):
                    df[k] = df[k] + df[v[ii]]
                    del df[v[ii]]
                    fea_list.remove(v[ii])
        fea_list = list(fea_list) + ['len_feature0']
  
        df1 = df[df['source']==1].copy()
        df2 = df[df['source']==2].copy()
        del df1['source']
        del df2['source']
        del df
        return df1,df2,fea_list

class AddressFeature(BaseFeatureExtraction):
    def __init__(self):
        super(AddressFeature,self).__init__()
        self.method_info = "Stree feature: street number, address number, etc."

    def normalize_num(self,x):
        if x[-1]=='1':
            return x+'st'
        elif x[-1]=='2':
            return x+'nd'
        elif x[-1]=='3':
            return x+'rd'
        else:
            return x+'th'

    def normalize_street(self,x):
        street_name_mapping = {'st.':'street','st':'street','st,':'street','st..':'street','street,':'street',
                       'ave':'avenue','ave.':'avenue','ave,':'avenue','avenue,':'avenue','pl':'place',
                       'blvd':'boulevard','pkwy':'parkway','dr':'drive','rd.':'road','rd,':'road','rd':'road',
                       'ln':'lane',
                       'e':'east','e.':'east','w.':'west','w':'west','west,':'west','s':'south','&':'and',
                       'second':'2nd','first':'1st','third':'3rd','fourth':'4th','fifth':'5th',
                       'sixth':'6th','seventh':'7th','eighth':'8th','ninth':'9th','tenth':'10th',                       
                       #'1':'1st','2':'2nd','43':'43rd','37':'37th','34':'34th',
                      }
        xlist = x.lower().strip(' .,').split()
        output = []
        for tt in xlist:
            tmp = tt.strip(',.*')
            if len(tmp)>0:
                if tmp in street_name_mapping:
                    tmp = street_name_mapping[tmp]
                elif tmp.isdigit():
                    tmp = self.normalize_num(tmp)
                else:
                    pass
                output.append(tmp)
        return ' '.join(output).strip()      

    def rem_streetname_xy(self,x,y):
        '''remove x from y
        '''
        pos = y.find(x)
        if pos>0:
            tmp = y.replace(x,'').strip(' ,.')
            tmp = tmp.split(' ')[0].strip(',. #')
            if '-' in tmp:        
                tmp = tmp.split('-')[0].strip(', .#')
            try:
                a = int(tmp)
                return a
            except ValueError:
                #print tmp
                return None
        else:
            return None   

    def rem_streetname(self,row):    
        x = row['display_address']
        y = row['street_address']
        return self.rem_streetname_xy(x,y)


    def get_address_num_simple(self,x):
        if len(x)==0:
            return -1
        
        x1 = x.strip().split()[0]
        if x1.isdigit():
            return float(x1)
        return -1

    def manhattan_locale(self,df1_,df2_):
        '''
        extract street or avenue number from displayed address. 
        
        For those displayed address like 'w 3rd street and 5th avenue', all three fields will have values. 
        For a majority cases, one of the (west_east, street) or (avenue) will be null (0)
        '''
        
        df1 = df1_.copy()
        df2 = df2_.copy()
        df1['source'] = 1
        df2['source'] = 2
        df = df1.append(df2)
        df = df.reset_index(drop=True)
        
        ave_mapping = {'lexington avenue': '3.5 avenue',
                      'park avenue':'4 avenue',
                      'madison avenue':'4.5 avenue',
                      'central park west':'8 avenue',
                      'columbus avenue':'9 avenue',
                      'amsterdam avenue':'10 avenue',
                      'west end avenue':'11 avenue'
                      }
        addr_adjust = {'central park west':5000,
                      'columbus avenue':5000,
                      'amsterdam avenue':5000,
                      'west end avenue':5000        
                    }       
        
        df['west_east'] = 0 #west = -1,east = 1, null=0
        df['street_num'] = 0 # street number e.g. 12nd street will be 12, if not on a street, empty
        df['ave_num'] = 0 #avenue number, if not on avenue, empty
        df['addr_num_adjust'] = 0 # for several avenues 
        
        #import pdb;pdb.set_trace()
        
        for inx,row in df.iterrows():
            addr_str = ''
            addr_ave = ''
            
            if ' and ' in row['display_address']:
                ss = row['display_address'].split(' and ')
                if len(ss)>2:
                    continue
                if ' street' in ss[0] and ' avenue' in ss[1]:
                    addr_str = ss[0].strip()
                    addr_ave = ss[1].strip()
                elif ' street' in ss[1] and ' avenue' in ss[0]:
                    addr_str = ss[1].strip()
                    addr_str = ss[0].strip()
                else:
                    continue
            else:            
                if ' street' in row['display_address']:
                    addr_str = row['display_address'].strip()
                if ' avenue' in row['display_address']:
                    addr_ave = row['display_address'].strip()
            
            if len(addr_str)>0:
                num = re.sub('\D+','',row['display_address'])
                if len(num)>0:
                    fields = addr_str.split()
                    west_east = 0
                    ii=0
                    while ii < len(fields):
                        if fields[ii].strip() == 'west':
                            west_east = -1
                            break
                        elif fields[ii].strip() == 'east':
                            west_east = 1
                            break
                        ii += 1
                    if ii<len(fields)-2:                    
                        df.set_value(inx,'west_east',west_east)   
                        try:
                            df.set_value(inx,'street_num',float(re.sub('\D+','',fields[ii+1])))
                        except ValueError:
                            pass
                            #print addr_str
                            #return None,None
            if len(addr_ave)>0:
                adjust = 0
                if addr_ave in addr_adjust:
                    adjust = addr_adjust[addr_ave]
                if addr_ave in ave_mapping:
                    addr_ave = ave_mapping[addr_ave]
                try:
                    df.set_value(inx,'ave_num',float(re.sub('\D+','',addr_ave.split()[0])))
                except ValueError:
                    #print addr_ave
                    pass
                df.set_value(inx,'addr_num_adjust',adjust)
        df['address_num'] = df['address_num'] + df['addr_num_adjust']    
        del df['addr_num_adjust']
        df1 = df[df['source']==1].copy()
        df2 = df[df['source']==2].copy()
        del df1['source']
        del df2['source']
        del df
        
        fea_list = ['west_east','street_num','ave_num']
        return df1,df2,fea_list
        

    def transform(self,train_df_,test_df_):        
        train_df = train_df_.copy()
        test_df = test_df_.copy()
        
        train_df['address_num'] = train_df['street_address'].map(self.get_address_num_simple)
        test_df['address_num'] = test_df['street_address'].map(self.get_address_num_simple)
        
        train_df['display_address'] = train_df['display_address'].map(lambda x:self.normalize_street(x))
        test_df['display_address'] = test_df['display_address'].map(lambda x:self.normalize_street(x))
        train_df['street_address'] = train_df['street_address'].map(lambda x:self.normalize_street(x))
        test_df['street_address'] = test_df['street_address'].map(lambda x:self.normalize_street(x))
        
        flist = ['address_num']
        train_df,test_df,ff1 = self.manhattan_locale(train_df,test_df)
        #train_df,test_df,ff2 = multiple_hashing(train_df,test_df,'display_address')
        #train_df,test_df,ff2 = simple_hashing(train_df,test_df,'street_address')
        
        flist = flist + ff1
        return train_df,test_df,flist

class GbmQuantPrice(BaseFeatureExtraction):
    def __init__(self,independent_var,output_name):
        #independent_var can be:
        # 1. ['longitude','latitude']
        # 2. ['longitude','latitude','bathrooms']
        # 3. ['polar_rho','polar_theta']
        # 4. ['polar_rho','polar_theta','bathrooms']
        
        super(GbmQuantPrice,self).__init__()
        self.method_info = r"Use GBM to predict quantile house price using GBM quantile regression"
        self.independent_var = independent_var
        self.output_name = output_name
        
    def transform(self,train_df_,test_df_):
        from sklearn.ensemble import GradientBoostingRegressor
    
        df1 = train_df_.copy()
        df2 = test_df_.copy()
        df1['source'] = 1
        df2['source'] = 2
        df = df1.append(df2)
        df = df.reset_index(drop=True)
    
        df[self.output_name] = 4
    
        for room in range(0,6):
            if room>=5:
                mask = (df['bedrooms']>=5)
            else:
                mask = (df['bedrooms']==room)
            tmp = df[mask].copy()
        
            jj = 0
            all_quantile = np.zeros((len(tmp),9))
            for alpha in np.arange(0.1,1,0.1):
                rgr = GradientBoostingRegressor(loss='quantile',alpha=alpha,n_estimators=100,max_depth=2)
                rgr.fit(tmp[self.independent_var],tmp['price'].as_matrix().ravel())
                pred = rgr.predict(tmp[self.independent_var])
                all_quantile[:,jj] = pred
                jj += 1
            quant_res = [np.searchsorted(all_quantile[ii,:],tmp['price'].iloc[ii]) for ii in range(len(tmp))]
            df.loc[mask,self.output_name] = quant_res
        
    
        df1 = df[df['source']==1].copy()
        df2 = df[df['source']==2].copy()
        del df1['source']
        del df2['source']
        del df
    
        return df1,df2,[self.output_name]


class PriceQuantileFeature(BaseFeatureExtraction):
    
    def __init__(self,axis_1='longitude',axis_2='latitude',step_size=0.02,nLevel=10):
        '''
        axis_1 = 'longitude'
        axis_2 = 'latitude'
        '''
        super(PriceQuantileFeature,self).__init__()
        self.method_info = r"Price Quantile over grid and over all listing for each (bathroom,bedroom) pair"
        self.axis_1 = axis_1
        self.axis_2 = axis_2
        self.step_size = step_size
        self.nLevel = nLevel

    def get_quantile_by_key(self,df,keys,nLevel,newcol_name):
        #keys is a list of keys to groupby on
        gp = df.groupby(keys)
        levels = np.arange(0,1,1./nLevel)
        res = pd.DataFrame()
        
        for inx,data in gp:
            quantiles = [data['price'].quantile(x) for x in levels]
            tmp = data.copy()
            tmp[newcol_name] = data['price'].map(lambda x:np.searchsorted(quantiles,x))
            
            res = res.append(tmp)
        
        df = res
        return df

    def quantile_price(self,df1_,df2_):
        df1 = df1_.copy()
        df2 = df2_.copy()
        df1['source'] = 1
        df2['source'] = 2
        df = df1.append(df2)
        df = df.reset_index(drop=True)
        
        df = self.get_quantile_by_key(df,['bedrooms','bathrooms'],self.nLevel,'price_quantile')
                    
        df1 = df[df['source']==1].copy()
        df2 = df[df['source']==2].copy()
        del df1['source']
        del df2['source']
        del df
        
        return df1,df2,['price_quantile']

    def quantile_price_lat_long(self,df1_,df2_,):
        df1 = df1_.copy()
        df2 = df2_.copy()
        df1['source'] = 1
        df2['source'] = 2
        df = df1.append(df2)
        df = df.reset_index(drop=True)
        
        west, south, east, north = -74.02, 40.64, -73.85, 40.86
        #import pdb;pdb.set_trace()
        df['long_grid'] = df[self.axis_1].map(lambda x: int(round((x-west)/self.step_size)))
        df['lat_grid'] = df[self.axis_2].map(lambda x:int(round((x-south)/self.step_size)))
        
        df = self.get_quantile_by_key(df,['long_grid','lat_grid','bedrooms','bathrooms'],self.nLevel,'price_quantile_lat_long')
                    
        df1 = df[df['source']==1].copy()
        df2 = df[df['source']==2].copy()
        del df1['source']
        del df2['source']
        del df
        
        return df1,df2,['price_quantile_lat_long','long_grid','lat_grid']

    def transform(self,train_df,test_df):
        train_df,test_df,fealist_quant1 = self.quantile_price_lat_long(train_df,test_df)
        train_df,test_df,fealist_quant2 = self.quantile_price(train_df,test_df)
        return train_df,test_df,fealist_quant1 + fealist_quant2



class Miscellous(BaseFeatureExtraction):
    def __init__(self):
        super(Miscellous,self).__init__()
        self.method_info = "Miscellous features"

    def transform(self,train_df_,test_df_):    
        train_df = train_df_.copy()
        test_df = test_df_.copy()
        
        train_df["created"] = pd.to_datetime(train_df["created"])
        test_df["created"] = pd.to_datetime(test_df["created"])

        test_df['days'] = test_df['created']-pd.to_datetime('2016-04-01')
        train_df['days'] = train_df['created'] - pd.to_datetime('2016-04-01')
        test_df['hours'] = test_df['days']/np.timedelta64(1,'h')
        train_df['hours'] = train_df['days']/np.timedelta64(1,'h')
        test_df['days'] = test_df['days']/np.timedelta64(1, 'D')
        train_df['days'] = train_df['days']/np.timedelta64(1,'D')
        
        train_df['hours'] = train_df['hours'].map(int)
        test_df['hours'] = test_df['hours'].map(int)
        gp = train_df.append(test_df).groupby('hours').size()
        gp.name = 'hour_size'
        gp = gp.reset_index()
        train_df = pd.merge(train_df,gp,on='hours')
        test_df = pd.merge(test_df,gp,on='hours')
        del test_df['hours']
        del train_df['hours']
        
        train_df['weekdays'] = train_df['created'].map(lambda x:x.weekday())
        test_df['weekdays'] = test_df['created'].map(lambda x:x.weekday())

        # Let us extract some features like year, month, day, hour from date columns #
        train_df["created_month"] = train_df["created"].dt.month
        test_df["created_month"] = test_df["created"].dt.month
        train_df["created_day"] = train_df["created"].dt.day
        test_df["created_day"] = test_df["created"].dt.day
        train_df["created_hour"] = train_df["created"].dt.hour
        test_df["created_hour"] = test_df["created"].dt.hour
        # count of photos #
        train_df["num_photos"] = train_df["photos"].apply(len)
        test_df["num_photos"] = test_df["photos"].apply(len)

        # count of "features" #
        train_df["num_features"] = train_df["features"].apply(len)
        test_df["num_features"] = test_df["features"].apply(len)

        # count of words present in description column #
        train_df["num_description_words"] = train_df["description"].apply(lambda x: len(x.split(" ")))
        test_df["num_description_words"] = test_df["description"].apply(lambda x: len(x.split(" ")))
        
        tmp = train_df.append(test_df)
        gp = tmp.groupby('manager_id').size()
        gp.name = 'manager_count'
        gp = gp.reset_index()
        train_df = pd.merge(train_df,gp,how='left')
        test_df = pd.merge(test_df,gp,how='left')
        
        gp = tmp.groupby('building_id').size()
        gp.name = 'building_count'
        gp = gp.reset_index()
        train_df = pd.merge(train_df,gp,how='left')
        test_df = pd.merge(test_df,gp,how='left')
        
        #train_df['price_per_bath'] = train_df['price'] / train_df['bathrooms']
        #train_df['price_per_room'] = train_df['price'] / (train_df['bathrooms'] + train_df['bedrooms'] )

        #test_df['price_per_bath'] = test_df['price'] / test_df['bathrooms']
        #test_df['price_per_room'] = test_df['price'] / (0.5*test_df['bathrooms'] + test_df['bedrooms'] )
        
        fea_list = ['weekdays','manager_count','building_count',"num_features","num_description_words","days","num_photos", "created_month", "created_day", "created_hour"]
        return train_df,test_df,fea_list
