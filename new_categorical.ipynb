{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import hashlib\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Column 'features' -- cleaning, transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_fea(df1_,df2_,nTop=300,combine=True):\n",
    "    ''' df1_ is training set\n",
    "        df2_ is test set\n",
    "    '''\n",
    "    from collections import defaultdict\n",
    "    df1 = df1_.copy() # Maybe ther eis better way to avoid SettingWithCopyWarning \n",
    "    df2 = df2_.copy()\n",
    "    df1['source'] = 1\n",
    "    df2['source'] = 2\n",
    "    df = df1.append(df2)\n",
    "    df = df.reset_index(drop=True)\n",
    "    #df['features'] = df['features'].map(lambda x:[tt.lower() for tt in x])\n",
    "    df['description'] = df['description'].map(lambda x:x.lower())\n",
    "    #---------------------------\n",
    "    #original length of the first feature, meant to capture those features typed in with wrong \n",
    "    # format -- all features are cramed into one phrase\n",
    "    df['len_feature0'] = df['features'].map(lambda x:0 if len(x)==0 else len(x[0])) \n",
    "    #-----------------------------\n",
    "    \n",
    "    def fea_clean(x): \n",
    "        if len(x) == 1:\n",
    "            tmp = x[0].strip('*').split('*')\n",
    "            if len(tmp) ==1:\n",
    "                tmp = tmp[0].split(u'\\u2022')\n",
    "            x = tmp\n",
    "        ret = [tt.encode('utf-8').decode('unicode_escape').encode('ascii','ignore').lower().strip() for tt in x]\n",
    "        return ret\n",
    "    df['features'] = df['features'].map(fea_clean)\n",
    "    \n",
    "    \n",
    "    all_fea = defaultdict(int)\n",
    "    for _,row in df.iterrows():\n",
    "        for xx in row['features']:\n",
    "            all_fea[xx] += 1\n",
    "    sorted_fea = sorted(all_fea.iteritems(),key=lambda (k,v): v,reverse=True)\n",
    "    \n",
    "    combined_fea = {'laundry in unit':['laundry in unit','in-unit washer/dryer','washer & dryer',\n",
    "                                        'washer/dryer','washer/dryer in unit'],\n",
    "                   'laundry in building':['laundry in building','laundry room',\n",
    "                                           'washer/dryer in building','on-site laundry'],\n",
    "                   'gym/fitness':['gym/fitness','fitness center','gym','gym in building'],\n",
    "                   'pre-war':['pre-war','prewar'],\n",
    "                    'live-in superintendent':['live-in superintendent','live-in super','live in super'],\n",
    "                    'hardwood floors':['hardwood floors','hardwood','hardwood floor','hardwood flooring'],\n",
    "                    'high ceiling':['high ceiling','high ceilings'],\n",
    "                    'full-time doorman':['full-time doorman','ft doorman','24/7 doorman','24 hour doorman',\n",
    "                                        '24-hour doorman','24hr doorman','full time doorman','24 hr doorman']\n",
    "                   #'garage':['garage','parking']\n",
    "                   }\n",
    "    \n",
    "    fea_list = set([v[0] for v in sorted_fea[:nTop]])\n",
    "    for k,v in combined_fea.iteritems():\n",
    "        fea_list = fea_list.union(set(v))\n",
    "    for fea in fea_list:\n",
    "        df[fea] = 0\n",
    "    #import pdb;pdb.set_trace()\n",
    "    for inx,row in df.iterrows():\n",
    "        notlist = []\n",
    "        if len(row['features']) == 0:\n",
    "            continue\n",
    "        for ff in row['features']:\n",
    "            if ff in fea_list:\n",
    "                df.set_value(inx,ff,1)\n",
    "            else:\n",
    "                notlist.append(ff)\n",
    "        #df.set_value(inx,'description',row['description'] + ' '.join(notlist))\n",
    "    print 'fea_list length is {}'.format(len(fea_list))\n",
    "    fea_list = set(fea_list)\n",
    "    if combine:        \n",
    "        for k,v in combined_fea.iteritems():\n",
    "            df[k] = df[v[0]]\n",
    "            #print k,v\n",
    "            for ii in range(1,len(v)):\n",
    "                df[k] = df[k] + df[v[ii]]\n",
    "                del df[v[ii]]\n",
    "                fea_list.remove(v[ii])\n",
    "    fea_list = list(fea_list) + ['len_feature0']\n",
    "    #print 'fea_list length is {}'.format(len(fea_list))\n",
    "    df1 = df[df['source']==1].copy()\n",
    "    df2 = df[df['source']==2].copy()\n",
    "    del df1['source']\n",
    "    del df2['source']\n",
    "    del df\n",
    "    return df1,df2,fea_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street_address and display address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_num(x):\n",
    "    if x[-1]=='1':\n",
    "        return x+'st'\n",
    "    elif x[-1]=='2':\n",
    "        return x+'nd'\n",
    "    elif x[-1]=='3':\n",
    "        return x+'rd'\n",
    "    else:\n",
    "        return x+'th'\n",
    "\n",
    "def normalize_street(x):\n",
    "    street_name_mapping = {'st.':'street','st':'street','st,':'street','st..':'street','street,':'street',\n",
    "                       'ave':'avenue','ave.':'avenue','ave,':'avenue','avenue,':'avenue','pl':'place',\n",
    "                       'blvd':'boulevard','pkwy':'parkway','dr':'drive','rd.':'road','rd,':'road','rd':'road',\n",
    "                       'ln':'lane',\n",
    "                       'e':'east','e.':'east','w.':'west','w':'west','west,':'west','s':'south','&':'and',\n",
    "                       'second':'2nd','first':'1st','third':'3rd','fourth':'4th','fifth':'5th',\n",
    "                       'sixth':'6th','seventh':'7th','eighth':'8th','ninth':'9th','tenth':'10th',                       \n",
    "                       #'1':'1st','2':'2nd','43':'43rd','37':'37th','34':'34th',\n",
    "                      }\n",
    "    xlist = x.lower().strip(' .,').split()\n",
    "    output = []\n",
    "    for tt in xlist:\n",
    "        tmp = tt.strip(',.*')\n",
    "        if len(tmp)>0:\n",
    "            if tmp in street_name_mapping:\n",
    "                tmp = street_name_mapping[tmp]\n",
    "            elif tmp.isdigit():\n",
    "                tmp = normalize_num(tmp)\n",
    "            else:\n",
    "                pass\n",
    "            output.append(tmp)\n",
    "    return ' '.join(output).strip()      \n",
    "\n",
    "def rem_streetname_xy(x,y):\n",
    "    '''remove x from y\n",
    "    '''\n",
    "    pos = y.find(x)\n",
    "    if pos>0:\n",
    "        tmp = y.replace(x,'').strip(' ,.')\n",
    "        tmp = tmp.split(' ')[0].strip(',. #')\n",
    "        if '-' in tmp:        \n",
    "            tmp = tmp.split('-')[0].strip(', .#')\n",
    "        try:\n",
    "            a = int(tmp)\n",
    "            return a\n",
    "        except ValueError:\n",
    "            #print tmp\n",
    "            return None\n",
    "    else:\n",
    "        return None   \n",
    "\n",
    "def rem_streetname(row):    \n",
    "    x = row['display_address']\n",
    "    y = row['street_address']\n",
    "    return rem_streetname_xy(x,y)\n",
    "\n",
    "\n",
    "def get_address_num_simple(x):\n",
    "    if len(x)==0:\n",
    "        return -1\n",
    "    \n",
    "    x1 = x.strip().split()[0]\n",
    "    if x1.isdigit():\n",
    "        return float(x1)\n",
    "    return -1\n",
    "\n",
    "def manhattan_locale(df1_,df2_):\n",
    "    '''\n",
    "    extract street or avenue number from displayed address. \n",
    "    \n",
    "    For those displayed address like 'w 3rd street and 5th avenue', all three fields will have values. \n",
    "    For a majority cases, one of the (west_east, street) or (avenue) will be null (0)\n",
    "    '''\n",
    "    \n",
    "    df1 = df1_.copy()\n",
    "    df2 = df2_.copy()\n",
    "    df1['source'] = 1\n",
    "    df2['source'] = 2\n",
    "    df = df1.append(df2)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    ave_mapping = {'lexington avenue': '3.5 avenue',\n",
    "                  'park avenue':'4 avenue',\n",
    "                  'madison avenue':'4.5 avenue',\n",
    "                  'central park west':'8 avenue',\n",
    "                  'columbus avenue':'9 avenue',\n",
    "                  'amsterdam avenue':'10 avenue',\n",
    "                  'west end avenue':'11 avenue'\n",
    "                  }\n",
    "    addr_adjust = {'central park west':5000,\n",
    "                  'columbus avenue':5000,\n",
    "                  'amsterdam avenue':5000,\n",
    "                  'west end avenue':5000        \n",
    "                }       \n",
    "    \n",
    "    df['west_east'] = 0 #west = -1,east = 1, null=0\n",
    "    df['street_num'] = 0 # street number e.g. 12nd street will be 12, if not on a street, empty\n",
    "    df['ave_num'] = 0 #avenue number, if not on avenue, empty\n",
    "    df['addr_num_adjust'] = 0 # for several avenues \n",
    "    \n",
    "    #import pdb;pdb.set_trace()\n",
    "    \n",
    "    for inx,row in df.iterrows():\n",
    "        addr_str = ''\n",
    "        addr_ave = ''\n",
    "        \n",
    "        if ' and ' in row['display_address']:\n",
    "            ss = row['display_address'].split(' and ')\n",
    "            if len(ss)>2:\n",
    "                continue\n",
    "            if ' street' in ss[0] and ' avenue' in ss[1]:\n",
    "                addr_str = ss[0].strip()\n",
    "                addr_ave = ss[1].strip()\n",
    "            elif ' street' in ss[1] and ' avenue' in ss[0]:\n",
    "                addr_str = ss[1].strip()\n",
    "                addr_str = ss[0].strip()\n",
    "            else:\n",
    "                continue\n",
    "        else:            \n",
    "            if ' street' in row['display_address']:\n",
    "                addr_str = row['display_address'].strip()\n",
    "            if ' avenue' in row['display_address']:\n",
    "                addr_ave = row['display_address'].strip()\n",
    "        \n",
    "        if len(addr_str)>0:\n",
    "            num = re.sub('\\D+','',row['display_address'])\n",
    "            if len(num)>0:\n",
    "                fields = addr_str.split()\n",
    "                west_east = 0\n",
    "                ii=0\n",
    "                while ii < len(fields):\n",
    "                    if fields[ii].strip() == 'west':\n",
    "                        west_east = -1\n",
    "                        break\n",
    "                    elif fields[ii].strip() == 'east':\n",
    "                        west_east = 1\n",
    "                        break\n",
    "                    ii += 1\n",
    "                if ii<len(fields)-2:                    \n",
    "                    df.set_value(inx,'west_east',west_east)   \n",
    "                    try:\n",
    "                        df.set_value(inx,'street_num',float(re.sub('\\D+','',fields[ii+1])))\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                        #print addr_str\n",
    "                        #return None,None\n",
    "        if len(addr_ave)>0:\n",
    "            adjust = 0\n",
    "            if addr_ave in addr_adjust:\n",
    "                adjust = addr_adjust[addr_ave]\n",
    "            if addr_ave in ave_mapping:\n",
    "                addr_ave = ave_mapping[addr_ave]\n",
    "            try:\n",
    "                df.set_value(inx,'ave_num',float(re.sub('\\D+','',addr_ave.split()[0])))\n",
    "            except ValueError:\n",
    "                #print addr_ave\n",
    "                pass\n",
    "            df.set_value(inx,'addr_num_adjust',adjust)\n",
    "    df['address_num'] = df['address_num'] + df['addr_num_adjust']    \n",
    "    del df['addr_num_adjust']\n",
    "    df1 = df[df['source']==1].copy()\n",
    "    df2 = df[df['source']==2].copy()\n",
    "    del df1['source']\n",
    "    del df2['source']\n",
    "    del df\n",
    "    \n",
    "    fea_list = ['west_east','street_num','ave_num']\n",
    "    return df1,df2,fea_list\n",
    "    \n",
    "\n",
    "def address_proc(train_df_,test_df_):        \n",
    "    train_df = train_df_.copy()\n",
    "    test_df = test_df_.copy()\n",
    "    \n",
    "    train_df['address_num'] = train_df['street_address'].map(get_address_num_simple)\n",
    "    test_df['address_num'] = test_df['street_address'].map(get_address_num_simple)\n",
    "    train_df['display_address'] = train_df['display_address'].map(lambda x:normalize_street(x))\n",
    "    test_df['display_address'] = test_df['display_address'].map(lambda x:normalize_street(x))\n",
    "    train_df['street_address'] = train_df['street_address'].map(lambda x:normalize_street(x))\n",
    "    test_df['street_address'] = test_df['street_address'].map(lambda x:normalize_street(x))\n",
    "    \n",
    "    flist = ['address_num']\n",
    "    train_df,test_df,ff1 = manhattan_locale(train_df,test_df)\n",
    "    #train_df,test_df,ff2 = multiple_hashing(train_df,test_df,'display_address')\n",
    "    #train_df,test_df,ff2 = simple_hashing(train_df,test_df,'street_address')\n",
    "    \n",
    "    flist = flist + ff1\n",
    "    return train_df,test_df,flist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# price quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quantile_by_key(df,keys,nLevel,newcol_name):\n",
    "    #keys is a list of keys to groupby on\n",
    "    gp = df.groupby(keys)\n",
    "    levels = np.arange(0,1,1./nLevel)\n",
    "    res = pd.DataFrame()\n",
    "    \n",
    "    for inx,data in gp:\n",
    "        quantiles = [data['price'].quantile(x) for x in levels]\n",
    "        #import pdb;pdb.set_trace()\n",
    "        tmp = data.copy()\n",
    "        tmp[newcol_name] = data['price'].map(lambda x:np.searchsorted(quantiles,x))\n",
    "        \n",
    "        res = res.append(tmp)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    df = res\n",
    "    return df\n",
    "\n",
    "def quantile_price(df1_,df2_,nLevel=10):\n",
    "    df1 = df1_.copy()\n",
    "    df2 = df2_.copy()\n",
    "    df1['source'] = 1\n",
    "    df2['source'] = 2\n",
    "    df = df1.append(df2)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df = get_quantile_by_key(df,['bedrooms','bathrooms'],nLevel,'price_quantile')\n",
    "                \n",
    "    df1 = df[df['source']==1].copy()\n",
    "    df2 = df[df['source']==2].copy()\n",
    "    del df1['source']\n",
    "    del df2['source']\n",
    "    del df\n",
    "    \n",
    "    return df1,df2,['price_quantile']\n",
    "\n",
    "def quantile_price_lat_long(df1_,df2_,step_size=0.02,nLevel=10):\n",
    "    df1 = df1_.copy()\n",
    "    df2 = df2_.copy()\n",
    "    df1['source'] = 1\n",
    "    df2['source'] = 2\n",
    "    df = df1.append(df2)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    west, south, east, north = -74.02, 40.64, -73.85, 40.86\n",
    "    df['long_grid'] = df['longitude'].map(lambda x: int(round((x-west)/step_size)))\n",
    "    df['lat_grid'] = df['latitude'].map(lambda x:int(round((x-south)/step_size)))\n",
    "    \n",
    "    df = get_quantile_by_key(df,['long_grid','lat_grid','bedrooms','bathrooms'],nLevel,'price_quantile_lat_long')\n",
    "                \n",
    "    df1 = df[df['source']==1].copy()\n",
    "    df2 = df[df['source']==2].copy()\n",
    "    del df1['source']\n",
    "    del df2['source']\n",
    "    del df\n",
    "    \n",
    "    return df1,df2,['price_quantile_lat_long','long_grid','lat_grid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CategoricalFeature:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prepare_categorical(self,df1_,df2_):\n",
    "        df1 = df1_.copy()\n",
    "        df2 = df2_.copy()\n",
    "        df1['source'] = 1\n",
    "        df2['source'] = 2\n",
    "        df = df1.append(df2)\n",
    "        df = df.reset_index(drop=True)\n",
    "    \n",
    "    #some of the building id is zero, whereas other rows with same street address have nonzero building_id\n",
    "    #nonzero = df[(df['building_id']!='0')&(df['street_address']!='')&(df['street_address'].notnull())]\n",
    "    #id_addr = nonzero.groupby('street_address')['building_id'].first().reset_index()\n",
    "    #del df['building_id']\n",
    "    #df = pd.merge(df,id_addr,on='street_address',how='left')\n",
    "    #df['building_id'] = df['building_id'].fillna('0')\n",
    "    \n",
    "    #assign those categorical data that only appear once to the same value\n",
    "        def objects_with_only_one_record(df,feature_name):\n",
    "            #import pdb;pdb.set_trace()\n",
    "            temp = df.groupby(feature_name, as_index = False).count()\n",
    "            return temp[temp['source'] == 1]\n",
    "\n",
    "        #import pdb;pdb.set_trace()\n",
    "        managers_with_one_lot = objects_with_only_one_record(df,'manager_id')\n",
    "        buildings_with_one_lot = objects_with_only_one_record(df,'building_id')\n",
    "        addresses_with_one_lot = objects_with_only_one_record(df,'display_address')\n",
    "\n",
    "        df.loc[df['manager_id'].isin(managers_with_one_lot['manager_id'].ravel()), \n",
    "          'manager_id'] = \"once\"\n",
    "        df.loc[df['building_id'].isin(buildings_with_one_lot['building_id'].ravel()), \n",
    "          'building_id'] = \"once\"\n",
    "        df.loc[df['display_address'].isin(addresses_with_one_lot['display_address'].ravel()), \n",
    "          'display_address'] = \"once\"\n",
    "                \n",
    "        df1 = df[df['source']==1].copy()\n",
    "        df2 = df[df['source']==2].copy()\n",
    "        del df1['source']\n",
    "        del df2['source']\n",
    "        del df\n",
    "    \n",
    "        return df1,df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class categorical_cv(CategoricalFeature):\n",
    "    def __init__(self,nfold,k=5.0,f=1.0,r_k=0.01,g=1.0):\n",
    "        self.k = k\n",
    "        self.f = f\n",
    "        self.r_k = r_k\n",
    "        self.g = g\n",
    "        self.nfold = nfold\n",
    "        \n",
    "    def cat2num(self,df_tr_,df_te_,cat_var,target):\n",
    "        #example: cat_var = 'building_id', target='medium'\n",
    "        dftrain = df_tr_.copy()\n",
    "        dftest = df_te_.copy()\n",
    "    \n",
    "        global_avg = dftrain[target].sum()*1.0/len(dftrain)\n",
    "        gp = dftrain.groupby(cat_var)\n",
    "        cat_avg = gp[target].agg({'avg':np.mean,\n",
    "                             'cnt':lambda x:len(x)})\n",
    "        cat_avg = cat_avg.reset_index()\n",
    "        cat_avg['beta'] = cat_avg['cnt'].map(lambda x:1./(self.g+np.exp((x-self.k)/self.f)) if x<200 else 0.)\n",
    "    \n",
    "        cat_avg['cat2num'] = cat_avg['avg']*(1-cat_avg['beta']) + global_avg*cat_avg['beta']\n",
    "        dftest = pd.merge(dftest,cat_avg[[cat_var,'cat2num']],on=cat_var,how='left')\n",
    "        dftest['cat2num'] = dftest['cat2num'].fillna(global_avg)\n",
    "    \n",
    "        return dftest['cat2num'].as_matrix()\n",
    "    def categorical_average(self,Xtrain_,Xtest_,variable,target):       \n",
    "        X_train = Xtrain_.copy()\n",
    "        X_test = Xtest_.copy()\n",
    "    \n",
    "        k_fold = StratifiedKFold(self.nfold,shuffle=True,random_state=222)\n",
    "        fea_name = variable + '_' + target\n",
    "        fea_train = np.zeros(len(X_train))\n",
    "        fea_test = np.zeros(len(X_test))\n",
    "    \n",
    "        for train_inx,cv_inx in k_fold.split(np.zeros((len(X_train),2)),X_train['interest_level'].ravel()):\n",
    "            fea_train[cv_inx] = self.cat2num(X_train.iloc[train_inx,:],X_train.iloc[cv_inx,:],variable,target)\n",
    "    \n",
    "        X_train[fea_name] = fea_train\n",
    "        X_test.loc[:,fea_name] = self.cat2num(X_train,X_test,variable,target)\n",
    "        return X_train,X_test,fea_name\n",
    "    \n",
    "    def transform(self,xtrain_,xtest_):\n",
    "        Xtrain,Xtest = self.prepare_categorical(xtrain_,xtest_)\n",
    "    \n",
    "        categorical = ['building_id', 'manager_id', 'display_address']\n",
    "        fea_list = categorical\n",
    "        for f in categorical:\n",
    "            encoder = preprocessing.LabelEncoder()\n",
    "            encoder.fit(list(Xtrain[f]) + list(Xtest[f])) \n",
    "            Xtrain[f] = encoder.transform(Xtrain[f].ravel())\n",
    "            Xtest[f] = encoder.transform(Xtest[f].ravel())\n",
    "    \n",
    "        Xtrain['low'] = 0\n",
    "        Xtrain.loc[Xtrain['interest_level'] == 0, 'low'] = 1\n",
    "        Xtrain['medium'] = 0\n",
    "        Xtrain.loc[Xtrain['interest_level'] == 1, 'medium'] = 1\n",
    "        Xtrain['high'] = 0\n",
    "        Xtrain.loc[Xtrain['interest_level'] == 2, 'high'] = 1\n",
    "    \n",
    "        for col in [\"building_id\", \"manager_id\"]:        \n",
    "            Xtrain,Xtest,fea1 = self.categorical_average(Xtrain,Xtest,col, \"medium\")\n",
    "            Xtrain,Xtest,fea2 = self.categorical_average(Xtrain,Xtest,col, \"high\")\n",
    "            fea_list += [fea1,fea2]\n",
    "    \n",
    "    \n",
    "        return Xtrain,Xtest,fea_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class categorical_lit(CategoricalFeature):\n",
    "    def __init__(self,nfold,k=5.0,f=1.0,r_k=0.01,g=1.0):\n",
    "        self.k = k\n",
    "        self.f = f\n",
    "        self.r_k = r_k\n",
    "        self.g = g\n",
    "        self.nfold = nfold\n",
    "        self.global_avg = None\n",
    "        \n",
    "    def cat2num(self,df_tr_,df_te_,cat_var,target):\n",
    "        #example: cat_var = 'building_id', target='medium'\n",
    "        dftrain = df_tr_.copy()\n",
    "        dftest = df_te_.copy()\n",
    "    \n",
    "        \n",
    "        gp = dftrain.groupby(cat_var)\n",
    "        cat_avg = gp[target].agg({'avg':np.mean,\n",
    "                             'cnt':lambda x:len(x)})\n",
    "        cat_avg = cat_avg.reset_index()\n",
    "        cat_avg['beta'] = cat_avg['cnt'].map(lambda x:1./(self.g+np.exp((x-self.k)/self.f)) if x<200 else 0.)\n",
    "    \n",
    "        cat_avg['cat2num'] = cat_avg['avg']*(1-cat_avg['beta']) + self.global_avg*cat_avg['beta']\n",
    "        \n",
    "        dftest = pd.merge(dftest,cat_avg[[cat_var,'cat2num']],on=cat_var,how='left')\n",
    "        dftest['cat2num'] = dftest['cat2num'].fillna(self.global_avg)\n",
    "        if self.r_k: \n",
    "            ratio = np.random.uniform(1 - self.r_k, 1 + self.r_k, len(dftest))\n",
    "        else:\n",
    "            ratio = 1\n",
    "        return dftest['cat2num'].as_matrix()*ratio\n",
    "    \n",
    "    def categorical_average(self,Xtrain_,Xtest_,variable,target):       \n",
    "        X_train = Xtrain_.copy()\n",
    "        X_test = Xtest_.copy()\n",
    "    \n",
    "        self.global_avg = X_train[target].sum()*1.0/len(X_train)\n",
    "        \n",
    "        k_fold = StratifiedKFold(self.nfold,shuffle=True,random_state=222)\n",
    "        fea_name = variable + '_' + target +'_lit'\n",
    "        fea_train = np.zeros(len(X_train))\n",
    "        fea_test = np.zeros(len(X_test))\n",
    "    \n",
    "        for train_inx,cv_inx in k_fold.split(np.zeros((len(X_train),2)),X_train['interest_level'].ravel()):\n",
    "            fea_train[cv_inx] = self.cat2num(X_train.iloc[train_inx,:],X_train.iloc[cv_inx,:],variable,target)\n",
    "    \n",
    "        X_train[fea_name] = fea_train\n",
    "        X_test.loc[:,fea_name] = self.cat2num(X_train,X_test,variable,target)\n",
    "        return X_train,X_test,fea_name\n",
    "    \n",
    "    def transform(self,xtrain_,xtest_):\n",
    "        Xtrain,Xtest = self.prepare_categorical(xtrain_,xtest_)\n",
    "    \n",
    "        categorical = ['building_id', 'manager_id', 'display_address']\n",
    "        fea_list = categorical\n",
    "        for f in categorical:\n",
    "            encoder = preprocessing.LabelEncoder()\n",
    "            encoder.fit(list(Xtrain[f]) + list(Xtest[f])) \n",
    "            Xtrain[f] = encoder.transform(Xtrain[f].ravel())\n",
    "            Xtest[f] = encoder.transform(Xtest[f].ravel())\n",
    "    \n",
    "        Xtrain['low'] = 0\n",
    "        Xtrain.loc[Xtrain['interest_level'] == 0, 'low'] = 1\n",
    "        Xtrain['medium'] = 0\n",
    "        Xtrain.loc[Xtrain['interest_level'] == 1, 'medium'] = 1\n",
    "        Xtrain['high'] = 0\n",
    "        Xtrain.loc[Xtrain['interest_level'] == 2, 'high'] = 1\n",
    "    \n",
    "        for col in [\"building_id\", \"manager_id\"]:        \n",
    "            Xtrain,Xtest,fea1 = self.categorical_average(Xtrain,Xtest,col, \"medium\")\n",
    "            Xtrain,Xtest,fea2 = self.categorical_average(Xtrain,Xtest,col, \"high\")\n",
    "            fea_list += [fea1,fea2]\n",
    "    \n",
    "    \n",
    "        return Xtrain,Xtest,fea_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getQuant(df1_,df2_,independent_var,output_name):\n",
    "    #independent_var can be:\n",
    "    # 1. ['longitude','latitude']\n",
    "    # 2. ['longitude','latitude','bathrooms']\n",
    "    # 3. ['polar_rho','polar_theta']\n",
    "    # 4. ['polar_rho','polar_theta','bathrooms']\n",
    "    \n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "    df1 = df1_.copy()\n",
    "    df2 = df2_.copy()\n",
    "    df1['source'] = 1\n",
    "    df2['source'] = 2\n",
    "    df = df1.append(df2)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df[output_name] = 4\n",
    "    \n",
    "    for room in range(0,6):\n",
    "        if room>=5:\n",
    "            mask = (df['bedrooms']>=5)\n",
    "        else:\n",
    "            mask = (df['bedrooms']==room)\n",
    "        tmp = df[mask].copy()\n",
    "        \n",
    "        jj = 0\n",
    "        all_quantile = np.zeros((len(tmp),9))\n",
    "        for alpha in np.arange(0.1,1,0.1):\n",
    "            rgr = GradientBoostingRegressor(loss='quantile',alpha=alpha,n_estimators=100,max_depth=2)\n",
    "            rgr.fit(tmp[independent_var],tmp['price'].as_matrix().ravel())\n",
    "            pred = rgr.predict(tmp[independent_var])\n",
    "            all_quantile[:,jj] = pred\n",
    "            jj += 1\n",
    "        quant_res = [np.searchsorted(all_quantile[ii,:],tmp['price'].iloc[ii]) for ii in range(len(tmp))]\n",
    "        df.loc[mask,output_name] = quant_res\n",
    "        \n",
    "    \n",
    "    df1 = df[df['source']==1].copy()\n",
    "    df2 = df[df['source']==2].copy()\n",
    "    del df1['source']\n",
    "    del df2['source']\n",
    "    del df\n",
    "    \n",
    "    return df1,df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def additional_feature(train_df_,test_df_):    \n",
    "    train_df = train_df_.copy()\n",
    "    test_df = test_df_.copy()\n",
    "    \n",
    "    train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "    test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "    test_df['days'] = test_df['created']-pd.to_datetime('2016-04-01')\n",
    "    train_df['days'] = train_df['created'] - pd.to_datetime('2016-04-01')\n",
    "    test_df['hours'] = test_df['days']/np.timedelta64(1,'h')\n",
    "    train_df['hours'] = train_df['days']/np.timedelta64(1,'h')\n",
    "    test_df['days'] = test_df['days']/np.timedelta64(1, 'D')\n",
    "    train_df['days'] = train_df['days']/np.timedelta64(1,'D')\n",
    "    \n",
    "    train_df['hours'] = train_df['hours'].map(int)\n",
    "    test_df['hours'] = test_df['hours'].map(int)\n",
    "    gp = train_df.append(test_df).groupby('hours').size()\n",
    "    gp.name = 'hour_size'\n",
    "    gp = gp.reset_index()\n",
    "    train_df = pd.merge(train_df,gp,on='hours')\n",
    "    test_df = pd.merge(test_df,gp,on='hours')\n",
    "    del test_df['hours']\n",
    "    del train_df['hours']\n",
    "    \n",
    "    train_df['weekdays'] = train_df['created'].map(lambda x:x.weekday())\n",
    "    test_df['weekdays'] = test_df['created'].map(lambda x:x.weekday())\n",
    "\n",
    "    # Let us extract some features like year, month, day, hour from date columns #\n",
    "    train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "    test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "    train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "    test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "    train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "    test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "    # count of photos #\n",
    "    train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "    test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "    # count of \"features\" #\n",
    "    train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "    test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "    # count of words present in description column #\n",
    "    train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "    test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "    \n",
    "    tmp = train_df.append(test_df)\n",
    "    gp = tmp.groupby('manager_id').size()\n",
    "    gp.name = 'manager_count'\n",
    "    gp = gp.reset_index()\n",
    "    train_df = pd.merge(train_df,gp,how='left')\n",
    "    test_df = pd.merge(test_df,gp,how='left')\n",
    "    \n",
    "    gp = tmp.groupby('building_id').size()\n",
    "    gp.name = 'building_count'\n",
    "    gp = gp.reset_index()\n",
    "    train_df = pd.merge(train_df,gp,how='left')\n",
    "    test_df = pd.merge(test_df,gp,how='left')\n",
    "    \n",
    "    #train_df['price_per_bath'] = train_df['price'] / train_df['bathrooms']\n",
    "    #train_df['price_per_room'] = train_df['price'] / (train_df['bathrooms'] + train_df['bedrooms'] )\n",
    "\n",
    "    #test_df['price_per_bath'] = test_df['price'] / test_df['bathrooms']\n",
    "    #test_df['price_per_room'] = test_df['price'] / (0.5*test_df['bathrooms'] + test_df['bedrooms'] )\n",
    "    \n",
    "    fea_list = ['weekdays','manager_count','building_count',\"num_features\",\"num_description_words\",\"days\",\"num_photos\", \"created_month\", \"created_day\", \"created_hour\"]\n",
    "    return train_df,test_df,fea_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data_path = \"../input/\"\n",
    "    train_file = data_path + \"train.json\"\n",
    "    test_file = data_path + \"test.json\"\n",
    "    train_df = pd.read_json(train_file)\n",
    "    test_df = pd.read_json(test_file)\n",
    "    interest_map = {'low':0,'medium':1,'high':2}\n",
    "    train_df['interest_level'] = train_df['interest_level'].map(interest_map)\n",
    "    fmt = lambda s: s.replace(\"\\u00a0\", \"\").strip().lower()\n",
    "    train_df[\"street_address\"] = train_df['street_address'].apply(fmt)\n",
    "    train_df[\"display_address\"] = train_df[\"display_address\"].apply(fmt)\n",
    "    #original_col = train_df.columns\n",
    "    test_df[\"street_address\"] = test_df['street_address'].apply(fmt)\n",
    "    test_df[\"display_address\"] = test_df[\"display_address\"].apply(fmt)\n",
    "    \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB_sklearn_calibration(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=2800,verbose=True):\n",
    "\n",
    "    clf = XGBClassifier(n_estimators=num_rounds,\n",
    "                            objective='multi:softprob',\n",
    "                            learning_rate=0.01,\n",
    "                            max_depth=6,\n",
    "                            min_child_weight=1,\n",
    "                            subsample=.7,\n",
    "                            colsample_bytree=.7,\n",
    "                            colsample_bylevel=.5,\n",
    "                            gamma=0.005,\n",
    "                            scale_pos_weight=1,\n",
    "                            base_score=.5,\n",
    "                            #reg_lambda=0,\n",
    "                            #reg_alpha=0,\n",
    "                            #missing=0,\n",
    "                            seed=seed_val)\n",
    "    \n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    clf_isotonic = CalibratedClassifierCV(clf, cv=3, method='isotonic')\n",
    "    clf_isotonic.fit(train_X, train_y)\n",
    "    prob_iso = clf_isotonic.predict_proba(test_X)\n",
    "\n",
    "    # Gaussian Naive-Bayes with sigmoid calibration\n",
    "    clf_sigmoid = CalibratedClassifierCV(clf, cv=3, method='sigmoid')\n",
    "    clf_sigmoid.fit(train_X, train_y)\n",
    "    prob_sig = clf_sigmoid.predict_proba(test_X)\n",
    "    \n",
    "    return prob_iso,prob_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB_sklearn(train_X, train_y,  test_X, test_y=None,sample_weight=None, feature_names=None, seed_val=0, num_rounds=5000,verbose=True):\n",
    "\n",
    "    clf = XGBClassifier(n_estimators=num_rounds,\n",
    "                            objective='multi:softprob',\n",
    "                            learning_rate=0.01,\n",
    "                            max_depth=6,\n",
    "                            min_child_weight=1,\n",
    "                            subsample=.7,\n",
    "                            colsample_bytree=.7,\n",
    "                            colsample_bylevel=.5,\n",
    "                            gamma=0.005,\n",
    "                            scale_pos_weight=1,\n",
    "                            base_score=.5,\n",
    "                            #reg_lambda=0,\n",
    "                            #reg_alpha=0,\n",
    "                            #missing=0,\n",
    "                            seed=seed_val)\n",
    "    \n",
    "    if test_y is not None:\n",
    "        clf.fit(train_X, train_y,sample_weight= sample_weight,eval_set=[(train_X, train_y), (test_X, test_y)],verbose=verbose,eval_metric='mlogloss',\n",
    "            early_stopping_rounds=50)\n",
    "    else:        \n",
    "        clf.fit(train_X, train_y,sample_weight = sample_weight,verbose=False)\n",
    "    pred_test_y = clf.predict_proba(test_X)\n",
    "    return pred_test_y, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X=None, test_y=None, feature_names=None, seed_val=0, num_rounds=5000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    #param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    \n",
    "    def custom_rates(boosting_round, num_boost_round):\n",
    "        total_round = max(boosting_round,num_boost_round)\n",
    "        curr_round = min(boosting_round,num_boost_round)\n",
    "        \n",
    "        if curr_round<100:\n",
    "            return 0.1\n",
    "        elif curr_round<300:\n",
    "            #print 'learning rate 0.01'\n",
    "            return 0.05\n",
    "        elif curr_round<1000:\n",
    "            return 0.01\n",
    "        elif curr_round<1500:\n",
    "            return 0.005\n",
    "        else:\n",
    "            return 0.001\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=30,verbose_eval=500, \n",
    "                          callbacks = [xgb.callback.reset_learning_rate(custom_rates)])\n",
    "    else:\n",
    "        \n",
    "        model = xgb.train(plst, xgtrain, num_rounds,verbose_eval=False,\n",
    "                          callbacks = [xgb.callback.reset_learning_rate(custom_rates)])\n",
    "    pred_test_y = None\n",
    "    if test_X is not None:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        pred_test_y = model.predict(xgtest)\n",
    "    \n",
    "    #plot_hist(test_y,pred_test_y)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB_gridsearch(X, y,seed_val=1234):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from time import time\n",
    "    \n",
    "    #import pdb;pdb.set_trace()\n",
    "    params = {}\n",
    "    params['n_estimators'] = np.logspace(3,3.8,3,dtype=int)\n",
    "    params['learning_rate'] = np.logspace(-4,-1,4)\n",
    "    params['max_depth'] = [6]\n",
    "    params['subsample'] = [0.7]\n",
    "    params['colsample_bytree'] = [0.7,0.4]\n",
    "    params['colsample_bylevel'] = [0.7]\n",
    "    params['gamma'] = np.logspace(-3,-1,3)\n",
    "\n",
    "    clf = XGBClassifier(objective='multi:softprob',\n",
    "                            min_child_weight=1,\n",
    "                            scale_pos_weight=1,\n",
    "                            base_score=.5,\n",
    "                            #reg_lambda=0,\n",
    "                            #reg_alpha=0,\n",
    "                            #missing=0,\n",
    "                            seed=seed_val)\n",
    "    \n",
    "    grid_search = GridSearchCV(clf, param_grid=params,verbose=1,n_jobs=-1,scoring= 'neg_log_loss')\n",
    "    start = time()\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "    report(grid_search.cv_results_)\n",
    "    return grid_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Global parameter\n",
    "feature_params = {}\n",
    "feature_params['nTextFea'] = 300 # Number of text features used}\n",
    "feature_params['nQuantLevel'] = 10 # number of levels for quantile computation\n",
    "feature_params['step_size'] = 0.02 # the step size when discreting latitude and longitude\n",
    "feature_params['category_nfold'] = 5 # n-fold to transform the categorical variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fea_list length is 303\n"
     ]
    }
   ],
   "source": [
    "train_df,test_df = read_data()\n",
    "train_df,test_df,fealist_txt = text_fea(train_df,test_df,nTop = feature_params['nTextFea'])\n",
    "train_df,test_df,fealist_addr = address_proc(train_df,test_df)\n",
    "#train_df,test_df,fealist_quant1 = quantile_price_lat_long(train_df,test_df,\n",
    "#                                step_size = feature_params['step_size'],nLevel=feature_params['nQuantLevel'])\n",
    "#train_df,test_df,fealist_quant2 = quantile_price(train_df,test_df,nLevel=feature_params['nQuantLevel'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df,test_df = getQuant(train_df,test_df,['latitude','longitude'],'gbm_quant_lat_long')\n",
    "fealist_quant_gbm = ['gbm_quant_lat_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ca = categorical_cv(feature_params['category_nfold'])\n",
    "train_df,test_df,fea_categorical = ca.transform(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df,test_df,fea_additional = additional_feature(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fealist = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",'listing_id'] \n",
    "fealist = fealist+ fealist_quant_gbm + fealist_txt+fealist_addr + fea_categorical+fea_additional\n",
    "#fealist = fealist+ fealist_quant1 + fealist_quant2+fealist_txt+fealist_addr + fea_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fea_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building_id', 'manager_id', 'display_address', 'building_id_medium', 'building_id_high', 'manager_id_medium', 'manager_id_high']\n",
      "['weekdays', 'manager_count', 'building_count', 'num_features', 'num_description_words', 'days', 'num_photos', 'created_month', 'created_day', 'created_hour']\n",
      "{'nTextFea': 300, 'step_size': 0.02, 'nQuantLevel': 10, 'category_nfold': 5}\n",
      "best iterations:3086, best_score=0.529339, last_score=0.52934440427\n",
      "Most important 40 features:\n",
      "[('price', 0.059359524), ('manager_id_medium', 0.053740036), ('manager_id_high', 0.049900956), ('listing_id', 0.049059097), ('latitude', 0.048526153), ('longitude', 0.047217377), ('building_id_medium', 0.04666321), ('building_id_high', 0.043349996), ('num_description_words', 0.042953826), ('days', 0.039279819), ('manager_id', 0.038940243), ('display_address', 0.038025279), ('address_num', 0.037695136), ('manager_count', 0.035912372), ('building_id', 0.035091732), ('gbm_quant_lat_long', 0.0302976), ('building_count', 0.028991181), ('created_day', 0.026767438), ('created_hour', 0.025531765), ('num_photos', 0.02345187), ('num_features', 0.020912135), ('len_feature0', 0.019758996), ('street_num', 0.018669527), ('bedrooms', 0.017813517), ('weekdays', 0.015311512), ('no fee', 0.0088360142), ('ave_num', 0.0075295949), ('bathrooms', 0.0074211196), ('furnished', 0.004225817), ('laundry in building', 0.0041998774), ('west_east', 0.0038390793), ('laundry in unit', 0.0037447531), ('dogs allowed', 0.0032707637), ('hardwood floors', 0.0032141679), ('pre-war', 0.0030019337), ('cats allowed', 0.0029689195), ('dishwasher', 0.0029547706), ('created_month', 0.0029500541), ('elevator', 0.0026835825), ('doorman', 0.002645852)]\n",
      "-------------------------\n",
      "best iterations:2506, best_score=0.531142, last_score=0.531149475785\n",
      "Most important 40 features:\n",
      "[('price', 0.061442167), ('manager_id_medium', 0.054691676), ('manager_id_high', 0.05062867), ('latitude', 0.048955496), ('longitude', 0.047481716), ('listing_id', 0.047230307), ('building_id_medium', 0.044927165), ('num_description_words', 0.043366689), ('building_id_high', 0.042728052), ('days', 0.039676461), ('manager_id', 0.037838571), ('address_num', 0.037780777), ('display_address', 0.036515061), ('manager_count', 0.036185626), ('building_id', 0.033567499), ('gbm_quant_lat_long', 0.033368107), ('building_count', 0.029469814), ('created_day', 0.026149476), ('created_hour', 0.024924217), ('num_photos', 0.02403128), ('num_features', 0.02108372), ('len_feature0', 0.019020427), ('street_num', 0.018769018), ('bedrooms', 0.01763623), ('weekdays', 0.014307222), ('no fee', 0.0096951583), ('ave_num', 0.0091085369), ('bathrooms', 0.0073284418), ('furnished', 0.0048837014), ('laundry in building', 0.0046005044), ('laundry in unit', 0.0037711423), ('west_east', 0.0035486303), ('hardwood floors', 0.0032365359), ('dogs allowed', 0.003025583), ('created_month', 0.0029446697), ('cats allowed', 0.0028406382), ('pre-war', 0.0028204098), ('dishwasher', 0.0026932601), ('elevator', 0.0025747798), ('exclusive', 0.002522764)]\n",
      "-------------------------\n",
      "best iterations:3480, best_score=0.522732, last_score=0.522762336513\n",
      "Most important 40 features:\n",
      "[('price', 0.059322529), ('manager_id_medium', 0.053630259), ('listing_id', 0.050341997), ('manager_id_high', 0.049708594), ('latitude', 0.049087733), ('longitude', 0.046953391), ('building_id_medium', 0.045820374), ('num_description_words', 0.044168923), ('building_id_high', 0.043951519), ('days', 0.040945463), ('manager_id', 0.040280703), ('display_address', 0.037797261), ('address_num', 0.037299737), ('manager_count', 0.036467742), ('building_id', 0.035552125), ('gbm_quant_lat_long', 0.029261991), ('building_count', 0.028467624), ('created_day', 0.028078802), ('created_hour', 0.024706921), ('num_photos', 0.02304711), ('num_features', 0.020603385), ('len_feature0', 0.019545622), ('street_num', 0.018492039), ('bedrooms', 0.017400829), ('weekdays', 0.014944562), ('ave_num', 0.0083262259), ('no fee', 0.0080586495), ('bathrooms', 0.0071681216), ('laundry in building', 0.0040366412), ('west_east', 0.0039467523), ('laundry in unit', 0.0035892869), ('dogs allowed', 0.0035265738), ('furnished', 0.0033802427), ('hardwood floors', 0.0033802427), ('pre-war', 0.0033238009), ('dishwasher', 0.0031272995), ('cats allowed', 0.0030959428), ('created_month', 0.0029036223), ('doorman', 0.0028283664), ('elevator', 0.0026025989)]\n",
      "-------------------------\n",
      "best iterations:3574, best_score=0.519642, last_score=0.519714448706\n",
      "Most important 40 features:\n",
      "[('price', 0.058965366), ('manager_id_medium', 0.053987782), ('listing_id', 0.050441407), ('manager_id_high', 0.050077993), ('latitude', 0.049040824), ('longitude', 0.047231909), ('building_id_medium', 0.045643494), ('num_description_words', 0.043861117), ('building_id_high', 0.04324045), ('manager_id', 0.041260034), ('days', 0.040896617), ('display_address', 0.037568703), ('address_num', 0.036994994), ('manager_count', 0.036306951), ('building_id', 0.035631161), ('gbm_quant_lat_long', 0.029295871), ('building_count', 0.028362829), ('created_day', 0.027776871), ('created_hour', 0.024867496), ('num_photos', 0.023056537), ('num_features', 0.021314997), ('street_num', 0.018926246), ('len_feature0', 0.018871121), ('bedrooms', 0.016555872), ('weekdays', 0.015183873), ('ave_num', 0.0085239569), ('no fee', 0.0083647072), ('bathrooms', 0.0073642903), ('laundry in building', 0.0042609577), ('west_east', 0.0039138743), ('furnished', 0.0039077494), ('laundry in unit', 0.0035953743), ('dogs allowed', 0.003542291), ('hardwood floors', 0.0032258327), ('pre-war', 0.003223791), ('dishwasher', 0.0031564161), ('created_month', 0.0030522912), ('cats allowed', 0.0030175829), ('doorman', 0.0026480411), ('elevator', 0.0025439162)]\n",
      "-------------------------\n",
      "best iterations:3393, best_score=0.521363, last_score=0.52142457476\n",
      "Most important 40 features:\n",
      "[('price', 0.058260046), ('manager_id_medium', 0.05358763), ('manager_id_high', 0.050179541), ('latitude', 0.049927969), ('listing_id', 0.049063582), ('longitude', 0.04641667), ('building_id_medium', 0.046197347), ('building_id_high', 0.044505127), ('num_description_words', 0.044376116), ('manager_id', 0.040535834), ('days', 0.039972477), ('display_address', 0.037884619), ('manager_count', 0.037237406), ('address_num', 0.036828864), ('building_id', 0.035917174), ('gbm_quant_lat_long', 0.029262261), ('building_count', 0.028449481), ('created_day', 0.027219558), ('created_hour', 0.024540393), ('num_photos', 0.023759864), ('num_features', 0.021603199), ('len_feature0', 0.019399229), ('street_num', 0.019246565), ('bedrooms', 0.016859828), ('weekdays', 0.015438536), ('no fee', 0.008590105), ('ave_num', 0.0082912249), ('bathrooms', 0.0069365902), ('furnished', 0.0041520633), ('laundry in building', 0.0038230803), ('west_east', 0.003657514), ('laundry in unit', 0.0033349819), ('hardwood floors', 0.0031844669), ('dogs allowed', 0.0031823167), ('created_month', 0.0030533038), ('pre-war', 0.0030253511), ('dishwasher', 0.0030059991), ('cats allowed', 0.0027286215), ('exclusive', 0.0025071495), ('elevator', 0.002453394)]\n",
      "-------------------------\n",
      "mean score=0.524879048007\n"
     ]
    }
   ],
   "source": [
    "simple_cv(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building_id', 'manager_id', 'display_address', 'building_id_medium_lit', 'building_id_high_lit', 'manager_id_medium_lit', 'manager_id_high_lit']\n",
      "['weekdays', 'manager_count', 'building_count', 'num_features', 'num_description_words', 'days', 'num_photos', 'created_month', 'created_day', 'created_hour']\n",
      "{'nTextFea': 300, 'step_size': 0.02, 'nQuantLevel': 10, 'category_nfold': 5}\n",
      "best iterations:3251, best_score=0.529497, last_score=0.529557960155\n",
      "Most important 40 features:\n",
      "[('manager_id_medium_lit', 0.059834111), ('price', 0.05749714), ('manager_id_high_lit', 0.056157216), ('building_id_medium_lit', 0.056096312), ('building_id_high_lit', 0.053574368), ('listing_id', 0.046906333), ('latitude', 0.046518344), ('longitude', 0.045268651), ('num_description_words', 0.041233089), ('days', 0.037626125), ('manager_id', 0.037405059), ('address_num', 0.036245599), ('display_address', 0.036220785), ('manager_count', 0.03468461), ('building_id', 0.033624403), ('gbm_quant_lat_long', 0.02909483), ('building_count', 0.027745884), ('created_day', 0.026279638), ('created_hour', 0.0243081), ('num_photos', 0.022595977), ('num_features', 0.020105615), ('len_feature0', 0.019095033), ('street_num', 0.01827619), ('bedrooms', 0.016994918), ('weekdays', 0.014646669), ('no fee', 0.008542574), ('ave_num', 0.0071282107), ('bathrooms', 0.0071146763), ('furnished', 0.0040874425), ('laundry in building', 0.0039408179), ('laundry in unit', 0.0036768937), ('west_east', 0.0036295226), ('dogs allowed', 0.0032460429), ('hardwood floors', 0.0031490449), ('pre-war', 0.0027836114), ('cats allowed', 0.0027768442), ('created_month', 0.0027745883), ('dishwasher', 0.0027723326), ('elevator', 0.0025805929), ('doorman', 0.0024835949)]\n",
      "-------------------------\n",
      "best iterations:2693, best_score=0.530358, last_score=0.530371424035\n",
      "Most important 40 features:\n",
      "[('manager_id_medium_lit', 0.059318613), ('price', 0.058825441), ('manager_id_high_lit', 0.056457143), ('building_id_medium_lit', 0.054647043), ('building_id_high_lit', 0.052853204), ('latitude', 0.047162782), ('listing_id', 0.04577269), ('longitude', 0.045515269), ('num_description_words', 0.041531969), ('days', 0.037990358), ('manager_id', 0.037060924), ('address_num', 0.036294069), ('manager_count', 0.035294183), ('display_address', 0.035188504), ('building_id', 0.032527551), ('gbm_quant_lat_long', 0.031709213), ('building_count', 0.028059212), ('created_day', 0.025365746), ('created_hour', 0.023691135), ('num_photos', 0.023119383), ('num_features', 0.020596627), ('len_feature0', 0.018455943), ('street_num', 0.018060325), ('bedrooms', 0.016919529), ('weekdays', 0.013881926), ('no fee', 0.0090613235), ('ave_num', 0.0086142188), ('bathrooms', 0.0070344489), ('furnished', 0.0046119536), ('laundry in building', 0.0044060145), ('laundry in unit', 0.0036391621), ('west_east', 0.0034982562), ('hardwood floors', 0.0032327031), ('dogs allowed', 0.0031188948), ('created_month', 0.0027693401), ('cats allowed', 0.0027666304), ('dishwasher', 0.0027422428), ('pre-war', 0.0027341135), ('elevator', 0.002482109), ('doorman', 0.0024766896)]\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-0d9001900c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-735795caf99c>\u001b[0m in \u001b[0;36msimple_cv\u001b[0;34m(train_df, test_df)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#import pdb;pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
      "\u001b[0;32m<ipython-input-114-cf98af98fb49>\u001b[0m in \u001b[0;36mrunXGB_sklearn\u001b[0;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, num_rounds, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         clf.fit(train_X, train_y,eval_set=[(train_X, train_y), (test_X, test_y)],verbose=verbose,eval_metric='mlogloss',\n\u001b[0;32m---> 21\u001b[0;31m             early_stopping_rounds=50)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    443\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simple_cv(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'prob_iso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-0286aff75618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interest_level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpreds_iso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB_sklearn_calibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mwrite_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_simple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orignal_gbx_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwrite_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_iso\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'iso_gbx_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-183-6bf97f05f6bb>\u001b[0m in \u001b[0;36mrunXGB_sklearn_calibration\u001b[0;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, num_rounds, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprob_pos_sigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_sigmoid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprob_iso\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprob_sig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'prob_iso' is not defined"
     ]
    }
   ],
   "source": [
    "train_X = train_df[fealist].as_matrix()\n",
    "test_X = test_df[fealist].as_matrix()\n",
    "train_y = np.array(train_df['interest_level'])\n",
    "preds_simple, model = runXGB_sklearn(train_X, train_y, test_X,num_rounds=3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write_output() got an unexpected keyword argument 'prefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-28cff1fd479d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds_iso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB_sklearn_calibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwrite_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_simple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orignal_gbx_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwrite_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_iso\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'iso_gbx_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwrite_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_sig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sig_gbx_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write_output() got an unexpected keyword argument 'prefix'"
     ]
    }
   ],
   "source": [
    "preds_iso, pred_sig = runXGB_sklearn_calibration(train_X, train_y, test_X,num_rounds=2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_output(preds_simple,test_df,prefix='orignal_gbx_')\n",
    "write_output(preds_iso,test_df,prefix= 'iso_gbx_')\n",
    "write_output(pred_sig,test_df,prefix='sig_gbx_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB_sklearn_balance(train_X, train_y, sample_weight,prior, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=5000,verbose=True):\n",
    "\n",
    "    clf = XGBClassifier(n_estimators=num_rounds,\n",
    "                            objective='multi:softprob',\n",
    "                            learning_rate=0.01,\n",
    "                            max_depth=6,\n",
    "                            min_child_weight=1,\n",
    "                            subsample=.7,\n",
    "                            colsample_bytree=.7,\n",
    "                            colsample_bylevel=.5,\n",
    "                            gamma=0.005,\n",
    "                            scale_pos_weight=1,\n",
    "                            base_score=.5,\n",
    "                            #reg_lambda=0,\n",
    "                            #reg_alpha=0,\n",
    "                            #missing=0,\n",
    "                            seed=seed_val)\n",
    "    \n",
    "    if test_y is not None:\n",
    "        clf.fit(train_X, train_y,sample_weight= sample_weight,eval_set=[(train_X, train_y), (test_X, test_y)],verbose=verbose,eval_metric='mlogloss',\n",
    "            early_stopping_rounds=50)\n",
    "    else:        \n",
    "        clf.fit(train_X, train_y,sample_weight = sample_weight,verbose=False)\n",
    "    pred_test_y = clf.predict_proba(test_X)\n",
    "    \n",
    "    import pdb;pdb.set_trace()\n",
    "    pred_test_y = pred_test_y*prior\n",
    "    pred_test_y = pred_test_y/np.sum(pred_test_y,axis=1)\n",
    "    \n",
    "    return pred_test_y, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unbalance_cv(train_df,test_df):\n",
    "    train_X = train_df[fealist].as_matrix()\n",
    "    test_X = test_df[fealist].as_matrix()\n",
    "    train_y = np.array(train_df['interest_level'])\n",
    "    prior = np.array(train_df['interest_level'].value_counts(),dtype=float)\n",
    "    prior = prior/np.sum(prior)\n",
    "    prior_inv = prior[-1]/prior\n",
    "    weights = np.ones(len(train_y))\n",
    "    for ii in range(len(prior)):\n",
    "        weights[train_y==ii] = prior_inv[ii]\n",
    "    cv_scores = [] \n",
    "    #print fea_categorical\n",
    "    #print fea_additional\n",
    "    #print feature_params\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "    for dev_index, val_index in kf.split(train_X,train_y):\n",
    "        import pdb;pdb.set_trace()\n",
    "        dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        dev_w, val_w = weights[dev_index], weights[val_index]\n",
    "        preds, model = runXGB_sklearn_balance(dev_X, dev_y,dev_w,prior, val_X, val_y,verbose=False)\n",
    "        print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
    "                                                                   model.best_score,log_loss(val_y, preds)))\n",
    "        importance_inx = np.argsort(model.feature_importances_*-1)\n",
    "        print('Most important 40 features:')\n",
    "        ff = [(fealist[x],model.feature_importances_[x]) for x in importance_inx[:40]]\n",
    "        print(ff)\n",
    "        print('-------------------------')\n",
    "          \n",
    "    \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "    print 'mean score={}'.format(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-239-d6339bf0da2c>(18)unbalance_cv()\n",
      "-> dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
      "(Pdb) prior\n",
      "array([ 0.69468309,  0.22752877,  0.07778813])\n",
      "(Pdb) weights[:10]\n",
      "array([ 0.34188263,  0.11197643,  1.        ,  0.11197643,  0.11197643,\n",
      "        0.34188263,  0.11197643,  0.11197643,  0.34188263,  0.11197643])\n",
      "(Pdb) c\n",
      "> <ipython-input-236-497750e2325c>(27)runXGB_sklearn_balance()\n",
      "-> pred_test_y = pred_test_y*prior\n",
      "(Pdb) pred_test_y[:4,:]\n",
      "array([[ 0.19686683,  0.55499774,  0.24813548],\n",
      "       [ 0.63096684,  0.36363775,  0.00539541],\n",
      "       [ 0.29651287,  0.59226078,  0.11122637],\n",
      "       [ 0.07181653,  0.45893225,  0.46925119]], dtype=float32)\n",
      "(Pdb) tt =np.argmax(pred_test_y,axis=1)\n",
      "(Pdb) tt.shape\n",
      "(9871,)\n",
      "(Pdb) np.sum(tt,axis=0)\n",
      "4875\n",
      "(Pdb) tt[:10]\n",
      "array([1, 0, 1, 2, 2, 0, 1, 1, 1, 0])\n",
      "(Pdb) np.sum(tt==2)\n",
      "903\n",
      "(Pdb) np.sum(tt==1)\n",
      "3069\n",
      "(Pdb) np.sum(tt==0)\n",
      "5899\n",
      "(Pdb) prior\n",
      "array([ 0.69468309,  0.22752877,  0.07778813])\n",
      "(Pdb) n\n",
      "> <ipython-input-236-497750e2325c>(28)runXGB_sklearn_balance()\n",
      "-> pred_test_y = pred_test_y/np.sum(pred_test_y,axis=1)\n",
      "(Pdb) n\n",
      "ValueError: 'operands could not be broadcast together with shapes (9871,3) (9871,) '\n",
      "> <ipython-input-236-497750e2325c>(28)runXGB_sklearn_balance()\n",
      "-> pred_test_y = pred_test_y/np.sum(pred_test_y,axis=1)\n",
      "(Pdb) tt = pred_test_y.T/np.sum(pred_test_y,axis=1)\n",
      "(Pdb) tt.shape\n",
      "(3, 9871)\n",
      "(Pdb) tt = tt.T\n",
      "(Pdb) tt.shape\n",
      "(9871, 3)\n",
      "(Pdb) tt[:5,:]\n",
      "array([[  4.84380719e-01,   4.47254914e-01,   6.83643671e-02],\n",
      "       [  8.40535036e-01,   1.58660141e-01,   8.04823680e-04],\n",
      "       [  5.89547284e-01,   3.85689361e-01,   2.47633554e-02],\n",
      "       [  2.61459867e-01,   5.47241177e-01,   1.91298956e-01],\n",
      "       [  5.02824255e-01,   3.52073693e-01,   1.45102053e-01]])\n",
      "(Pdb) test_y[:5,:]\n",
      "*** IndexError: too many indices for array\n",
      "(Pdb) test_y[:5]\n",
      "array([ 2.,  1.,  0.,  1.,  2.])\n",
      "(Pdb) pred_test_y[:5,:]\n",
      "array([[  1.36760055e-01,   1.26277955e-01,   1.93019958e-02],\n",
      "       [  4.38321997e-01,   8.27380500e-02,   4.19699249e-04],\n",
      "       [  2.05982479e-01,   1.34756368e-01,   8.65209199e-03],\n",
      "       [  4.98897318e-02,   1.04420292e-01,   3.65021742e-02],\n",
      "       [  1.21556465e-01,   8.51129061e-02,   3.50780465e-02]])\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-a8ec57bbcd6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munbalance_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-239-d6339bf0da2c>\u001b[0m in \u001b[0;36munbalance_cv\u001b[0;34m(train_df, test_df)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdev_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdev_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-236-497750e2325c>\u001b[0m in \u001b[0;36mrunXGB_sklearn_balance\u001b[0;34m(train_X, train_y, sample_weight, prior, test_X, test_y, feature_names, seed_val, num_rounds, verbose)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_test_y\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_test_y\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_test_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpred_test_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c_call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_exception\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unbalance_cv(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0027036747767468787, 0.46006753549545532)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(preds_simple[:,0],pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.45206132e-01,   4.78140554e-02,   6.97981468e-03],\n",
       "       [  9.51696919e-01,   3.91251743e-02,   9.17792226e-03],\n",
       "       [  9.94452688e-01,   5.15242516e-03,   3.94887566e-04],\n",
       "       [  9.79844915e-01,   1.86162812e-02,   1.53880138e-03],\n",
       "       [  9.89451905e-01,   9.73770690e-03,   8.10384734e-04]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43452139,  0.47143835,  0.09404026],\n",
       "       [ 0.98532992,  0.01069244,  0.00397763],\n",
       "       [ 0.74043381,  0.22978159,  0.02978459],\n",
       "       [ 0.41151256,  0.48588327,  0.10260417],\n",
       "       [ 0.68752913,  0.25054251,  0.06192836]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_iso[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = (pred+preds_iso)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_output(pp,test_df,prefix='merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_output(preds,test_df,prefix=''):\n",
    "    out_df = pd.DataFrame(preds)\n",
    "    out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "    out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "    \n",
    "    import time\n",
    "    filename = prefix + time.strftime(\"%Y.%m.%d.\") + str(np.random.randint(0,100000))+'.res.csv'\n",
    "    out_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_train_cv(train_df,test_df,fealist,target_col='interest_level',cv_fold=5,verbose=True):\n",
    "    train_X = train_df[fealist].as_matrix()\n",
    "    test_X = test_df[fealist].as_matrix()\n",
    "    train_y = np.array(train_df[target_col])\n",
    "    \n",
    "    kf = model_selection.StratifiedKFold(n_splits=cv_fold, shuffle=True, random_state=2016)\n",
    "    best_iteration = 0\n",
    "    print('Cross_validating to find the best iteration number')\n",
    "    for dev_index, val_index in kf.split(X_tr,y_tr):\n",
    "        dev_X, val_X = X_tr[dev_index,:], X_tr[val_index,:]\n",
    "        dev_y, val_y = y_tr[dev_index], y_tr[val_index]\n",
    "        preds, model = runXGB_sklearn(dev_X, dev_y, val_X, val_y,verbose=False)\n",
    "        \n",
    "        if verbose:\n",
    "            print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
    "                                                                   model.best_score,log_loss(val_y, preds)))\n",
    "            importance_inx = np.argsort(model.feature_importances_*-1)\n",
    "            print('Most important 20 features:')\n",
    "            ff = [(fealist[x],model.feature_importances_[x]) for x in importance_inx[:20]]\n",
    "            print(ff)\n",
    "            print('-------------------------')\n",
    "        tmp = model.best_iteration\n",
    "        best_iteration = tmp if tmp>best_iteration else best_iteration\n",
    "        cv_scores.append(log_loss(val_y, preds))    \n",
    "    print 'mean score={}'.format(np.mean(cv_scores))\n",
    "    \n",
    "    preds, model = runXGB_sklearn(X_tr, y_tr, X_te,num_rounds=int(best_iteration*1.02))\n",
    "    return pred\n",
    "\n",
    "def xgb_train_cv_np(X_tr,y_tr,X_te,cv_fold=5,verbose=True):\n",
    "    #import pdb;pdb.set_trace()\n",
    "    kf = model_selection.StratifiedKFold(n_splits=cv_fold, shuffle=True)\n",
    "    best_iteration = 0\n",
    "    cv_scores = []\n",
    "    print('Cross_validating to find the best iteration number')\n",
    "    for dev_index, val_index in kf.split(X_tr,y_tr):\n",
    "        dev_X, val_X = X_tr[dev_index,:], X_tr[val_index,:]\n",
    "        dev_y, val_y = y_tr[dev_index], y_tr[val_index]\n",
    "        preds, model = runXGB_sklearn(dev_X, dev_y, val_X, val_y,verbose=False)\n",
    "        \n",
    "        if verbose:\n",
    "            print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
    "                                                                   model.best_score,log_loss(val_y, preds)))            \n",
    "            print('-------------------------')\n",
    "        tmp = model.best_iteration\n",
    "        best_iteration = tmp if tmp>best_iteration else best_iteration\n",
    "        cv_scores.append(log_loss(val_y, preds))    \n",
    "    print 'mean score={}'.format(np.mean(cv_scores))\n",
    "    \n",
    "    preds, model = runXGB_sklearn(X_tr, y_tr, X_te,num_rounds=int(best_iteration*1.02))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_cv(train_df,test_df):\n",
    "    train_X = train_df[fealist].as_matrix()\n",
    "    test_X = test_df[fealist].as_matrix()\n",
    "    train_y = np.array(train_df['interest_level'])\n",
    "    \n",
    "    cv_scores = [] \n",
    "    #print fea_categorical\n",
    "    #print fea_additional\n",
    "    #print feature_params\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "    for dev_index, val_index in kf.split(train_X,train_y):\n",
    "        dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB_sklearn(dev_X, dev_y, val_X, val_y,verbose=False)\n",
    "        print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
    "                                                                   model.best_score,log_loss(val_y, preds)))\n",
    "        importance_inx = np.argsort(model.feature_importances_*-1)\n",
    "        print('Most important 40 features:')\n",
    "        ff = [(fealist[x],model.feature_importances_[x]) for x in importance_inx[:40]]\n",
    "        print(ff)\n",
    "        print('-------------------------')\n",
    "          \n",
    "    \n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "    print 'mean score={}'.format(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacking(X_train,y_train,X_test,nClass,nFold=9):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    pred = np.zeros((X_test.shape[0],nClass))\n",
    "    kfold = StratifiedKFold(nFold,shuffle=True)\n",
    "    for tr_inx,cv_inx in kfold.split(X_train,y_train):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        rf = RandomForestClassifier(100)\n",
    "        rf.fit(X_train[cv_inx,:],y_train[cv_inx])\n",
    "        tr_pred = rf.predict_proba(X_train[tr_inx,:])\n",
    "        te_pred = rf.predict_proba(X_test)\n",
    "        X_train_ex = np.hstack((X_train[tr_inx,:],tr_pred))\n",
    "        X_test_ex = np.hstack((X_test,te_pred))\n",
    "        #pred += xgb_train_cv_np(X_train_ex,y_train[tr_inx],X_test_ex)\n",
    "        tmp,_ = runXGB_sklearn(X_train_ex,y_train[tr_inx],X_test_ex,num_rounds=2800)\n",
    "        pred += tmp\n",
    "    pred = pred/nFold\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = train_df[fealist].as_matrix()\n",
    "test_X = test_df[fealist].as_matrix()\n",
    "train_y = np.array(train_df['interest_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = stacking(train_X,train_y,test_X,nClass=3,nFold=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(pred)\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('stacking_gbm_quant.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df['pred'] = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = pd.get_dummies(test_df['pred'],prefix='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_0    0.761663\n",
       "pred_1    0.195824\n",
       "pred_2    0.042513\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.sum()*1./len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.694683\n",
       "1.0    0.227529\n",
       "2.0    0.077788\n",
       "Name: interest_level, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['interest_level'].value_counts()*1.0/len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df['high'] = out_df['high']*.077788/.042513\n",
    "out_df['medium'] = out_df['medium']*.227529/.195824\n",
    "out_df['high'] = out_df['high']*.694683/.761663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sump = out_df[['high','medium','low']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df['high'] = out_df['high']/sump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df['medium']=out_df['medium']/sump\n",
    "out_df['low'] = out_df['low']/sump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttt = np.argmax(out_df[['low','medium','high']].as_matrix(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13346013206713189"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ttt[ttt>1])*1./len(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6919418827100846"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_low/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23109374898212232"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_med/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07696436830779321"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_high/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low = out_df.copy()\n",
    "low['low']=1\n",
    "low['medium']=0\n",
    "low['high']=0\n",
    "low.to_csv('all_low.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high = out_df.copy()\n",
    "high['low']=0\n",
    "high['medium']=0\n",
    "high['high']=1\n",
    "high.to_csv('all_high.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "med = out_df.copy()\n",
    "med['low']=0\n",
    "med['medium']=1\n",
    "med['high']=0\n",
    "med.to_csv('all_med.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b,c=31.88052,26.55708,10.63995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = (a+b+c)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_high = total-a\n",
    "n_med = total-b\n",
    "n_low = total-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = test_df.join(tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = tmp[(tmp['longitude']<-73.95)&(tmp['longitude']>-74.05)&(tmp['latitude']<41)&(tmp['latitude']>40.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low = tmp[tmp['pred']==0]\n",
    "med = tmp[tmp['pred']==1]\n",
    "high = tmp[tmp['pred']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f239d5ff750>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2UVPWd5/H3l+5GGiIDJMpCI2lEJBuigZOeQMI8GA3R\nAQMdMyM6MOtscuJ4NjPxYaLpXhlHk7j0xMRw9kxm9qBnctiDQUzGtCawUYJxNocVMo2gBJUAimiL\nQESSjBLCw3f/qFttdVEPt6puddW99Xmdw+lbt+7v1v3R1fd7f8/m7oiIiIQxrNYXICIi8aGgISIi\noSloiIhIaAoaIiISmoKGiIiEpqAhIiKhKWiIiEhoChoiIhKagoaIiITWXOsLiMJ73vMeb29vr/Vl\niIjEytatW3/p7ueUkiYRQaO9vZ2+vr5aX4aISKyY2culplH1lIiIhKagISIioSloiIhIaAoaIiIS\nmoKGiIiEpqAhIiKhKWiIiEhoChoiIhKagoaIiISmoCEiIqEpaIiISGgKGiIiEpqChoiIhKagISIi\noSloiIhIaKGDhpk1mdk2M/th8HqcmW0ws93Bz7F50t1sZjvN7OdmtsbMRgT77zSzfjPbHvybn5Gm\n28z2mNkuM7u80kyKiEg0Silp3Ag8n/G6C9jo7tOAjcHrQcysDfgC0OHuHwCagGsyDvmmu88M/q0P\n0rw/OGYGcAXwT2bWVMJ1iohIlYQKGmY2CVgA3J+xexGwKtheBXTmSd4MtJpZMzASeK3Ixy0CHnT3\n4+7+ErAH+HCY6xQRkeoKW9JYAdwGnM7YN97dDwTbrwPjsxO5ez/wdWA/cAD4lbs/nnHI35jZs2b2\nLxnVW23AKxnHvBrsExGRGisaNMzsSuCQu2/Nd4y7O+A50o4lVXKYAkwERpnZ0uDtfwbOB2aSCijf\nKOXCzex6M+szs77Dhw+XklRERMoUpqQxF1hoZvuAB4FLzWw1cNDMJgAEPw/lSPtx4CV3P+zuJ4CH\ngY8CuPtBdz/l7qeB+3inCqofOC/jHJOCfYO4+0p373D3jnPOOSdENkREpFLNxQ5w926gG8DMLgG+\n6O5Lzewe4DqgJ/j5SI7k+4E5ZjYSOAZcBvQF55qQUb31KeDnwfajwHfM7F5SpZNpwM/Kyp2IlOSC\n7nWczKgzaDbYs3xB7S5I6k4l4zR6gHlmtptUiaIHwMwmmtl6AHffAnwPeBrYEXzeyiD918xsh5k9\nC3wMuDlIsxN4CHgO+BHweXc/VcF1ikgI2QED4KSn9oukWao5It46Ojq8r6+v1pchEiu92/q557Fd\nvHb0GBPHtNJ/9FjeY/f1qLSRRGa21d07SklTtHpKRJKnd1s/3Q/v4NiJVCG+UMAQyaRpREQa0D2P\n7RoIGCKlUNAQaUCvlVCyaLYqXojEjoKGSAOaOKY11HHqPSXZ1KYh0oBuvXz6oDYNgNaWJpZfdRGd\nszQBg+SnoCHSgNKBIbP31K2XT1fAkKIUNEQaVOesNgUJKZnaNEREJDQFDRERCU1BQ0REQlPQEBGR\n0BQ0REQkNAUNEREJTUFDRERCU9AQEZHQNLhPRIZc9loeGo0eHwoaIjKkcq3l0f3wDgAFjhhQ0BCR\nIZVrLY9jJ05xz2O7Yh002rvOXBY3iSseqk1DRIZUvrU8Slnjo97kChjp/fPufXJoL6bKQgcNM2sy\ns21m9sPg9Tgz22Bmu4OfY/Oku9nMdprZz81sjZmNCPbfY2YvmNmzZvZ9MxsT7G83s2Nmtj3497+i\nyKiI1Id8a3mEXeOj3lzQnTtgpO0+9Bbnd62jd1v/EF1RdZVS0rgReD7jdRew0d2nARuD14OYWRvw\nBaDD3T8ANAHXBG9vAD7g7hcDvwC6M5LudfeZwb8bSrhGEalzt14+ndaWpkH7WluauPXy6TW6ovJd\n0L2Ok178uNNA98M7EhE4QgUNM5sELADuz9i9CFgVbK8COvMkbwZazawZGAm8BuDuj7v7yeCYzcCk\n0i5dROKoc1Yby6+6iLYxrRjQNqY1Vos/9W7rZ27PE7R3hQsYael2m7gL2xC+ArgNODtj33h3PxBs\nvw6Mz07k7v1m9nVgP3AMeNzdH89x/s8AazNeTzGz7cCvgGXu/tOQ1ykiMRCXtTyyuwZ/7H3nsHrz\n/rLP1x/jdpu0oiUNM7sSOOTuW/Md4+4OnBFzg3aORcAUYCIwysyWZh1zO3ASeCDYdQCY7O4zgVuA\n75jZ6Bznvt7M+sys7/Dhw8WyISJSkiX3PcVNa7fTf/QYTuqGX0nASIowJY25wEIzmw+MAEab2Wrg\noJlNcPcDZjYBOJQj7ceBl9z9MICZPQx8FFgdvP5L4ErgsiDw4O7HgePB9lYz2wtcCPRlntjdVwIr\nATo6OkooJIqI5Lesd4eCQwFFSxru3u3uk9y9nVQj9hPuvhR4FLguOOw64JEcyfcDc8xspJkZcBlB\nY7qZXUGqymuhu7+dTmBm55hZU7B9PjANeLHM/ImIhKaAUVwlg/t6gIfM7LPAy8DVAGY2Ebjf3ee7\n+xYz+x7wNKkqqG0EpQPgH4GzgA2peMLmoKfUHwFfNrMTpDod3ODuRyq4ThGRgvKNs5AzWVArFGsd\nHR3e19dX/EARkSxDGTDaxrSyqevSIfu8Ysxsq7t3lJJGI8JFRIZIHMeiZFPQEBEZAkvnTI5FN+Ni\nNGGhiEgVjRrexN2fis/gxWIUNEQktDivg5F57dVuya23tosoKWiISChxXgcj+9qrLc4z9hajNg0R\nCaXQOhj17kv/+myogLGvZwH7ehawYvHMnO+PHdmChfg8J9Ura1nvjtIuNAZU0hCJiVpXDcV1HYwl\n9z3F8ZOnQx/fu62fm9Zuz/nem2+fYNq5o4DUlOfFpAcKfrXzotCfX+9U0hCJgXT1SuY8SEM91XZc\n18HYtLe0scHFSk7pYJEOHsWs3rw/EVOipyloiMRAPVQNJWkdjHzau9aFmol296G3QpU00pKylgYo\naIjEQj1UDcV9HYxaikvbTxhq0xCJgYljWnM+AQ911VBc1sHINHfquJKrqKqh3tt+wlJJQyQGGqFq\nKGrpFfb+394jnNVc+1tdvbf9hFX7/0kRKUpVQ6XJ7jhw/ORpWluaWLF4Jvt6FoTqNttkxr6eBaEb\nvAtJUoBX9ZRITMSxaigq8+59clDD87RzR7HhlkvyHl+o40DnrDY+GqLK6pQ7S+57ij0lNHjnYsCn\nP5Sc351KGiJS17IDBqR6L00pMKV5sY4D+94I176wae+RiqccceAnLyRnSWoFDRGpa/m6tjow++4N\nZ+xv71qX90afblcY6kbppDSCg6qnRCTGDv7md4NeF1tQqf/osZqs0peURnBQ0BCROhZmQFwclmpN\nSiM4KGiISB2ZUqBqKc66vvdMYhrCFTREpKZyNXQnzW9POct6dyRi4sLQDeFm1mRm28zsh8HrcWa2\nwcx2Bz/H5kl3s5ntNLOfm9kaMxtRLL2ZdZvZHjPbZWaXV5pJEalP7V3rEh8w0tZseaXWlxCJUnpP\n3Qg8n/G6C9jo7tOAjcHrQcysDfgC0OHuHwCagGsKpTez9wfHzACuAP7JzJqyzx0H6RGpU7rWMbfn\nicRMWCYShTi0RUTplCej4i1U0DCzScAC4P6M3YuAVcH2KqAzT/JmoNXMmoGRwGtF0i8CHnT34+7+\nErAH+HCY66wn9TCVtUi9WnLfU7W+hCHXZGHGode/sG0aK4DbgLMz9o139wPB9uvA+OxE7t5vZl8H\n9gPHgMfd/fEi6duAzRmneTXYFyvFRqSKNJJGK1Xkcu3s82p9CZEoWtIwsyuBQ+6+Nd8x7u5wZqeH\noJ1iETAFmAiMMrOlYdMXua7rzazPzPoOH66/0Zb1MJW1SD1o9IDRZMbSOZMT0QgO4Uoac4GFZjYf\nGAGMNrPVwEEzm+DuB8xsAnAoR9qPAy+5+2EAM3sY+ChQKH0/kBmSJwX7BnH3lcBKgI6OjrqrLCxn\nKutaL+cpEpU4B4rxZw8/Y9BguUY0GS/cPT+Sc9WLoiUNd+9290nu3k6qgfoJd18KPApcFxx2HfBI\njuT7gTlmNtLMDLiMdxrT86V/FLjGzM4ysynANOBnJeesxkqdylptIMnVCB0ilvXu4PzudbR3rYt1\nwFixeCZbbp8Xycy2SQwYUNncUz3APDPbTapE0QNgZhPNbD2Au28Bvgc8DewIPm9lofTuvhN4CHgO\n+BHweXcf3DgQA6VOZV0Py3lK9BrhYWBZ7w5Wb97P6bor75dm6ZzJA3+fG2655IzAMe3cUYxoCt+Y\nncSAAWCegG5gHR0d3tfXV+vLqEi+kbAGvNSzYKgvRyIyt+eJnNWUbWNa2dR1aQ2uKHpxLlkAjB3Z\nwt9/ckZJVcEX//2P+PXxws+ybTGoYjazre7eUUoajQivE/WynKdEK+kdIuIaMAwqajd89q4rBrYv\n6F7HyRxPfP1Hj3HT2u3ctHY7KxbPrOvgUQoFjTpx6+XT6X54x6AqqiSt9tWokvowENdgAUR+A9+z\nPFUTkK9UCXDT2u0AiQgcChp1Iv1lUu+pZIn7w8D7bl/Pb0+98xjdbOR8qo6LqANG77b+gYBQTFLG\naClo1JFGXs4zqeL8MJAdMCCeAaNaVUOlBAxITpWkgoZIlcX1YSA7YMRNOQ3cpSi1Z2PcqyTTFDRE\nZMCS+55i094jtb6Miu2LuMdhFG04camSLEZrhIsIkJyAMXfquEjPV2nAGEb1qshqQSUNSQxNw1KZ\npASMBz73kVpfxiCnSfWeSsp3UUFDEiE98jrdSyk98hqS0c2x2uI6Qn2YwZ/PjmYywFwPHVFq71oX\nebVZLShoSCJUMhW9Sihw1w921voSShZllU++h47s75QoaEhClDvyutFKKL3b+rnz0Z0cPXYCSD2p\nx3XOqJvWbudvH3qGa2efV3FJI99DR9R6t/XH/nuloCGJUO7I60ZZLKt3Wz93/WAnb759YtD+uAaM\ntFPurN68H6CswDH77g2RTYMexp2P7oz990q9pyQRSp2KPi3pc0NBKmDcvHb7GQEjjvItmbpmyysl\nn2uoAwYwUMKLM5U0JBHKHXmd1LmhMn3xu8+UtixmnRh9VtOgiQEhf/fXU2XM1j3UASMpFDQkMcoZ\neR33uaEy5WvQPxnTOqjsgAGpkkauAJGvBJJPrSZcHDuypSafGyUFDWlocZ4bKlN6IaS0zGm5k+Ta\n2ecNymfm/mzz7n2S3YfeGng9+qymomtgVNuCiyfU9POjoEWYRGIs16SCSVBoPMOy3h2s2fIKp9xp\nMsvZeyo7YNSLsSNb2HbHJ2p9GQO0CJNIA0lSwBh/9nC23D4v1LFf7byoYE+pZb076jJgAInojKCg\nIRJTcQoY6WWLqzmQMruKTqpDQUMkhuK2cl66N1q1polPymSLcRA6aJhZE9AH9Lv7lWY2DlgLtAP7\ngKvd/c2sNNODY9LOB+5w9xVmthZId1EZAxx195lm1g48D6Qnq9/s7jeUmC+RRIlbkMhWzd5ovdv6\nFTCGUCkljRtJ3cxHB6+7gI3u3mNmXcHrL2UmcPddwEwYCDr9wPeD9xanjzOzbwC/yki6191nlpYV\nkeSJe7CA1BKxUZcuktSeEzehRoSb2SRgAXB/xu5FwKpgexXQWeQ0l5EKBi9nnduAq4E1Ya5FpFEk\nIWAA7Fke7cyuChi1FXYakRXAbaSmhk8b7+4Hgu3XgfFFznENuQPDHwIH3X13xr4pZrbdzP7NzP4w\n18nM7Hoz6zOzvsOHD4fLhYgMmWGWmok2agoYtVW0esrMrgQOuftWM7sk1zHu7maW9zdpZsOBhUB3\njrevZXAwOQBMdvc3zOxDQK+ZzXD3X2d95kpgJaTGaRTLh0i9S0rJAt4ZuZ1eRztugyUlvzAljbnA\nQjPbBzwIXGpmq4GDZjYBIPh5qMA5/gR42t0PZu40s2bgKjIay939uLu/EWxvBfYCF4bOkUgMxT1g\nzJ06jn09C1ixeCatLU0DU32kp5qPapGnZb07IjmPlK9o0HD3bnef5O7tpKqYnnD3pcCjwHXBYdcB\njxQ4TXZpIu3jwAvu/mp6h5mdEzSaY2bnA9OAF0PkRURqIHOJ1UJTzVdK4zDqQyXjNHqAh8zss8DL\npBqzMbOJwP3uPj94PQqYB/xVjnPkauf4I+DLZnaCVBvKDe6u/nRS1xp19b/s6T6immq+FtOWSzgl\nBQ13fxJ4Mth+g1SPqOxjXgPmZ7x+C3h3nvP9ZY59/wr8aynXJVJLjbb6HwwuXWSKYqp5BYz6phHh\nIhVqlNX/oPBEghDNVPMKGPVNQUOkQlFUyezrWRCLxvDMa8y1SFLYqeazZ6Gddu4oNtxySfUuXCKj\noCFSoUqqZOLcuPvr46cGBZEVi2cOzC1VqISVKzjuPvQW8+59UoEjBhQ0RCpUbpVMnANGLjet3c7y\n9c/R3NSUt5RRqDS1+9BbtHetwyCWy9OGUeoKg/VIQUOkQmGrZLJ7WOUqncRdZntEuR0CkhowIPcK\ng3GjoCESgWJVMrl6WDWCpHYIKFW+FQbjSEFDJALFxmkkba3uUpQ6RiNpivU4ixsFDZEK5Kqj7z96\njJvWbm/oQJGplDEacdJscDJEXVr6O5KU4KGgIVKmOHSRrbV0h4B0SSyujdzpnmHZerf1c+ejOzl6\nLLX299iRLXnXAW/vWpeIwKGgISJVs/yqVB1+du+yOGkb05q3TWb5+ucGAgaQN2AkiYKGiFTF0jmT\n6ZzVxtyeJ2IbMCD/UrUXdK8LVT2VNAoaIhK58WcPH+gpFOeG8OxqKVVJhl+5T0QktF/+xzvVNHFs\nCG9taVLAyENBQxpW77Z+5vY8wZSudczteaLkhYKS0KhZLelFmCBVvTMsJgOhjVQbxvKrLop8bElS\nvi+qnpKGFNV05isWz+SWtds5XZWrTIa+l49wOiZ1/y9V4cbebLBneTICBihoSIOKajrzex7bVdcB\nI/PpthbVK73b+mMzv1Y1SgJJCxigoCENKqoV5uq5kbetxm0J9d4G0BbxCov5FqZKGgUNaUiFpjMv\ndrPLfCKt14kHW5qM9ne3MrV7PafcEzG7alRaW5rKarPIt+ZJUtoqwjL3mFQ2FtDR0eF9fX21vgyJ\ngfTI5P6jx84Yndza0hTr8QTVNnfqOJ478JtYDmBrG9PacOu3h2FmW929o5Q0oUsaZtYE9AH97n6l\nmY0D1gLtwD7gand/MyvN9OCYtPOBO9x9hZndCXwOOBy899/dfX2Qrhv4LHAK+IK7P1ZKpkRyyW78\ndhgIHOmqikabL2oYhG6T2bT3CHEsrzRaSaDaSqmeuhF4HhgdvO4CNrp7j5l1Ba+/lJnA3XcBM2Eg\n6PQD38845Jvu/vXMNGb2fuAaYAYwEfixmV3o7noElIrkCgjpgLGp69K8xyRZqY34cauXqDRgFJu9\nuBGFChpmNglYANwN3BLsXgRcEmyvAp4kK2hkuQzY6+4vF/m4RcCD7n4ceMnM9gAfBp4Kc60iucy+\ne0Pe96JszF6xeGbkgWfu1HFMOeddsemFVGtG6V1ncwUHIJJu2UkTtqSxArgNODtj33h3PxBsvw6M\nL3KOa4A1Wfv+xsz+C6lqr78NqrfagM0Zx7wa7BMpW+aKctmah0XX0+dbP9kdyXkybdp7hE17j0R+\n3iRaOmdyyQsd5Rqzky/wa1GpEEHDzK4EDrn7VjO7JNcx7u5mlrfkambDgYVAd8bufwa+QqrE+xXg\nG8Bnwl64mV0PXA8wefLksMlEznAiwoEWuw+9Fd3JJKeou7bmGrNTSD13sx4KYUoac4GFZjYfGAGM\nNrPVwEEzm+DuB8xsAnCowDn+BHja3Q+md2Rum9l9wA+Dl/1A5kK6k4J9g7j7SmAlpHpPhciHiMRU\nOVVOYZUaBEYOb6rKdcRF0bmn3L3b3Se5ezupKqYn3H0p8ChwXXDYdcAjBU5zLVlVU0GgSfsU8PNg\n+1HgGjM7y8ymANOAn4XIi0he488eXutLkApUc9LDUs/91u9OharOXNa7g6nd62nvWsfU7vUs691R\n7iXWlUomLOwB5pnZbuDjwWvMbKKZrU8fZGajgHnAw1npv2ZmO8zsWeBjwM0A7r4TeAh4DvgR8Hn1\nnJJKbbl9Xq0vQUJqyprdML36X9TSE1aWOzizUOBY1ruD1Zv3D0zceMqd1Zv3JyJwlDQi3N2fJNVL\nCnd/g1SPqOxjXgPmZ7x+C3h3juP+osDn3E2qp5ZIZJrMBs2+KvVn7tRx/FnH5Kp3c81u/K70XNnX\nu2bLKzmPXbPllZIb6uuNphGRhnHt7PPUbbXOpRu4q907qdTG73yW9e7ggc37B8avpLvl5ns4ScJD\ni4KGNIz0E96aLa8k4o9XyhdVD6jMgJFWKBglYQ4wLcIkDeWrnRexd/l89vUsiOWUGEk2lJ0VompY\nL/XR49rZ5xU/qM4paEjDSfdqUVmjfow/e/iQdlaIomG90ENH25hWls6ZPFCyaDIra+BhPVL1lDSU\ndK8WqR+1mFCwc1Zb2dO9GPDNxTMHZkvO9X668T4JQSKbgoYkWr0vBNToajkDbb71MdKmnTuKV9/8\n7aA2CgOWzJk80FCf3QMr+/0kUtCQxFLAqG/Tzh1V60sYCFpL7ntq0Pxe6alKCs1ym/7ZaLPgahGm\nhGvkqZ0VNOpfva91cUH3Ok7muUWawZLZ8W6nKGcRJjWEJ1h6AFP/0WM47/Qh7912xlReIpJlSlf+\ngAHgDqs372fJfY21aoOqpxIs1wAmTe0skltmqfz3WltC967btPfIwPQg6TFATWZcO/u8WJdC8lHQ\nSLB8A5gafWpnSa5yq2OzR3YfPVbaOujZPfLSc00BiQscChoJNnFMa84ugdWcMbReqD2j/kU9uDLX\nYkqFVtpb1ruj6rMDJGGuqWxq06gT6Rk3p3StY27PE5G0O9x6+XRaWwbP/V+tGUNFSvXNxTMjPV+h\n6thsS+57atAstNWSxOlqVNKoA6U+IYUVty6BjdzTqxG0jWmt6u82bHVs77b+IVs+NwlzTWVT0KgD\n1Wyw7pzVdsY5Movl9dJgV63AKfWj/+ixqnaxDVsdm6vkUS1JmGsqm6qn6kA1GqzzVXfV6+IwpVQt\nFKMuxY0pbHXsUHUEScpcU9lU0qiiYtUt6Sf+fLWe5TZYF3pqr9fFYaIMnEP5JCn1I2x1bL4SSdRW\nb97Pmi2v1EVJPkoKGlVSrLql2MR5lTRYF3pqr9fFYaLs6aUuxY0rV3Vstlsvn172ZIWlSmLXW1VP\nVUmx6pZ8T/yQajBcftVFZdfl57tpFnq6qnWDXZQ9vRqhS7GUr3NWG2NHtgzpZyZpZmUFjSopVt1S\n6Ml+U9elFTX+5rtpFgoLc84fW/bnRaFzVhvLr7qItjGtGJUFzlwBSGovbCN4er2T9q51TO1eX5X2\ntr//5Iwh/45c0J2MsUOhq6fMrAnoA/rd/UozGwesBdqBfcDV7v5mVprpwTFp5wN3uPsKM7sH+CTw\nO2Av8F/d/aiZtQPPA+mK6c3ufkPpWautYtUtTWY5A0cUT/y3Xj4955TNhSqg9r1x5rUOdRfYMFUL\nYc8D5F3vYO7UcUPW5VJSSgkYmU/l1areSX9H7vrBTt58u7TR3+UqNI9VnJRS0riR1M08rQvY6O7T\ngI3B60HcfZe7z3T3mcCHgLeB7wdvbwA+4O4XA78AujOS7k2ni2PAgOLVLfm64kXRRS/XU3ux72uu\nvuxxneywvWsdN63dnrc6btPeI7QMg2HJ60Jfd5bOmVxSN9tCHTWi1jmrjW13fIKlcyZHfu4kC1XS\nMLNJwALgbuCWYPci4JJgexXwJPClAqe5jFQweBnA3R/PeG8z8KdhLzoOivXkSD81VWu8RPZT+9ye\nJwq2aeTqyx7HyQ7DTh9y4nQqiB8/eYrTCXkCrDfljMmoRUeNr3ZeRMd7x+UtmcpgYaunVgC3AWdn\n7Bvv7geC7deB8UXOcQ2wJs97n2FwNdYUM9sO/ApY5u4/DXmddaVYdctXOy8ash4Vuaqs0krpy95/\n9BhTutbV1YjtdDVaqX/wuf4vpLaqWW1bSPpvtXdbP7d+9xlOVOFJojkhJdui1VNmdiVwyN235jvG\nUys55f1fNrPhwELguzneux04CTwQ7DoATA6qtG4BvmNmo3Oku97M+sys7/Dhw8Wy0fAyq6zgnT/C\nfA3OhXog1VN1Ve+2/oJVUVIb5d7kq1ltG0bnrDbu+bMPMqZ1cO8qg4qqsZoN9iyv7wWnwgpT0pgL\nLDSz+cAIYLSZrQYOmtkEdz9gZhOAQwXO8SfA0+5+MHOnmf0lcCVwWRB4cPfjwPFge6uZ7QUuJNUI\nP8DdVwIrIbVyX4h8NLxSGpoLlUzS6qG6aqj620tpyr3JV7vaNoxc3ykPru2BLfspp6YsKQEDQgQN\nd+8maKQ2s0uAL7r70qD303VAT/DzkQKnuZasqikzu4JUldcfu/vbGfvPAY64+ykzOx+YBrxYSqak\nctltMvn+TuI8kK5lmFWlGkIq6+lUbrVtrjnVwoyPGH1WE8/edQVQuE2s0HuN1COvkhHhPcBDZvZZ\n4GXgagAzmwjc7+7zg9ejgHnAX2Wl/0fgLGCDpYqy6a61fwR82cxOAKeBG9y9MX4bVVZqF9rMkkm+\nhvRaDqSrtGqs1qPgJRq51vHO7KpbzK+Pn6po/ZX0HFPz7n2S3YfeOuP9uVPHlX3uemSegD+cjo4O\n7+vrK35gA8ue1gRSDeBhB9BVmr4Suf6gVyyeWbT6TGpj7tRxPPC5jwzJZ+UKGENt2rmjePHw2wUf\nQka2DON/XHVxXXQcyWRmW929o5Q0mnuqQVTahbZWa3PkewJUW0Z9yK6WyQwYQzEFf60DBpCzdJHt\n7ROnueWh1He23gJHqRQ0GkQUs8hGNWK7GC3VGh9TznlXzlLFUIzsjtv35LRT844jUdDcUw0iX9tD\nvU3uF7cbQaMrdQR3VCO74/o9iXPHkTQFjQah9cKj15SQwVqVKHUEdxSdD2q9YFgl6u0hrRwKGjWW\nb4W9qEU5i6yk7E1Q3/tsRqqzwYrFM2kpEB3zDeIrdX9Yvdv6eSDG04wn4SFNbRo1NNTrYg9Vm0Qj\nqPX6I9knogO0AAALoklEQVSmnTuKV9/8bSS9yQxYMmcynbPamPXlxzlxKn/poNAI7lxdXisd2X3P\nY7uKTr4p1aWgUUNhezTNvnsDB3/zu4HX488ezpbb5w3ZdcqZ0je/Ma0tHD02NFNrF5KvB8/YkS2M\nHN4cepqVtqxecYWmDS+0Bna1RnbHfbqYJDSEK2jUUJgeTdkBA+Dgb37H7Ls3JCZwxK1RM/NmeefC\nGXknuGsb08rH3ncOP3nhcM1udkffPsG2Oz5RdJZjSJUwNnVdGvrcxQJAlBNypucYi7skNIQraNRQ\nmHWxswNGsf1xE7eAkT3dd9jxK2Hz2dJkjBrezK+OnWBiEHQqWSo0/V0KM5dYrkbafCWp7An9qiVu\n349iktAQrqBRQ7n+kNWjqf60tjTx6Q+18ZMXDuecFj7KtqJ7/vSDZ5yrkqCR/i5lr2aYvZJjvu9d\nrpJUyzDjzoUzyr6msJIWMFqGWSL+thU0aqhWo6ylNMdOnOKBzfsHbrLldFgYf/bwUKXDqH/3mefL\nDG5h5yHTdzQ67xrRnIj/N809VedytWlAMhrD8+UtjsLMtxQmv/lWuyv3qbuc1fPqRdJKGga8VGe/\nj3LmntI4jTq35fZ5jD97+KB9SQgYkJx2GUitO77kvqcKHrPl9nns61mQd9bTQrOhZr83d+o49vUs\niHVQqAcjW4buFpiE9gxQ9VQsJCFANIKw6yk88LmPsOS+p/JO9Jct+9j0Zy257yke+NxHGNFk/DbH\nWIoRGrKeV2bX4tR4qWc5duJ0VT/zY+87p6rnHyoKGiI1UMrU4fmCUXr/C3fP5323rx8UOEY0GS/c\nPb+yiwyUug5LVPb1LIi8iirXdP652nqq0UX6Jy8kY1lqBQ2RBMgOEOnpaSq90Q/1rAXZ9vUsKDrG\nZBip1doyX//5nMkD42OazDjlfsbAxVzSASTfgkqVSMIYDVDQEIlMNVZoKzYXWfpJPLNtI9eN/ua1\n2+l7+UjJg+0qXYclCrdePr3gwL57F8+MvCS04ZZLIg8catMQkQHlrlZXqOqnlFHQ7V3rBgJHrhu9\nkxrvseXFN9hwyyWhry+KdVgq1TmrjeXrn8vZcWLauaOqNqda+v8p83f0e60tmBWeXiWXJI2/UtAQ\nqVDbmNayA0ahqp9Sp81o71rH6LOa+PXx/KO+dx96a6ABHYqvrhdm1oKhsOX2eWc8+U87d1RJAbBc\nhYJSvqBfq3agoaBxGlJT9doXf2TLMN4OetOMaW3hzoUzuHnt9pwzrJbb/75QXf20c0dFXqeeaV/P\ngjNW10vLnFurlmvDS/VVdY1wM2sC+oB+d7/SzMYBa4F2YB9wtbu/mZVmenBM2vnAHe6+olB6M+sG\nPgucAr7g7o+VkimJj8y6+GW9O/jOlv3kmPtvSOUb+5CvV025T92FqniqGTDSCq2ulw4aGhEu2UoZ\n2XIj8HzG6y5go7tPAzYGrwdx913uPtPdZwIfAt4Gvl8ovZm9H7gGmAFcAfxTELAk4b7aeREv1nhh\no6VzJud9L+rVD2vdMBp2db3OWW1s6rqUl3oWsKnrUgWMBhcqaJjZJGABcH/G7kXAqmB7FdBZ5DSX\nAXvd/eUi6RcBD7r7cXd/CdgDfDjMdUoytFXxZpoe7tY2ppW5U8cNLKbUZFZwfQiIfvXDXEFoKKR7\neVVrdT1JtrDVUyuA24CzM/aNd/cDwfbrwPgi57gGWBMifRuwOeO4V4N9g5jZ9cD1AJMn5386lPi5\n9fLpedeoKJUB31w8M7Kn4yh76qTPM5TrRGT28qrW6nqSbEWDhpldCRxy961mdkmuY9zdzSzvX7iZ\nDQcWAt3lpM+TZiWwElIN4aWklfqWvpne+ejOgqviLZ0zmY73juOuH+zM2QUyc9nSetU5q41v/WR3\nwTaMtjGtgxZHKtR5ILv3VKGuwNVaXU+SrWjvKTNbDvwFcBIYAYwGHgZ+H7jE3Q+Y2QTgSXfPWblr\nZouAz7v7JzL27cqVPmgEx92XB8c9Btzp7nlng1PvqeQr1jUUajfdRRTyDSRTTyWppnJ6T5XU5TYo\naXwx6D11D/CGu/eYWRcwzt1vy5PuQeAxd/92xr6c6c1sBvAdUu0YE0k1kk9z97ydzxU0JCniHPgk\nfqra5TaHHuAhM/ss8DJwdXARE4H73X1+8HoUMA/4qzDp3X2nmT0EPEeqdPP5QgFDJEmqNbpZJCoa\n3Cci0qC0CJOIiFSVgoaIiISmoCEiIqEpaIiISGgKGiIiEpqChoiIhKagISIioSloiIhIaAoaIiIS\nmoKGiIiEpqAhIiKhKWiIiEhoChoiIhKagoaIiISmoCEiIqEpaIiISGgKGiIiEpqChoiIhKagISIi\noSloiIhIaObutb6GipnZb4Bdtb6OKngP8MtaX0QVKF/xkcQ8gfKV9l53P6eUD2gu7Xrq1i5376j1\nRUTNzPqUr/hIYr6SmCdQviqh6ikREQlNQUNEREJLStBYWesLqBLlK16SmK8k5gmUr7IloiFcRESG\nRlJKGiIiMgTqOmiY2Voz2x7822dm27Pen2xm/2FmX8yTfpyZbTCz3cHPsRnvXWxmT5nZTjPbYWYj\nqp2fjM+uWr7CpK+GauXJzOaZ2dbgd7TVzC4divxkXFc1v4PdZrbHzHaZ2eXVzkvWdeXMl5l9OGP/\nM2b2qTzpPxj8/ewwsx+Y2ehgf4uZrQr2P29m3UnIV/Be3d0zoshX8H74e4a7x+If8A3gjqx93wO+\nC3wxT5qvAV3BdhfwD8F2M/As8MHg9buBprjnK2z6OOUJmAVMDLY/APQn5Dv4fuAZ4CxgCrC3Hr6D\nwEigOdieABxKv85K8+/AHwfbnwG+Emz/OfBgxrn2Ae0JyFdd3jMqzVfY73Hmv7ouaaSZmQFXA2sy\n9nUCLwE7CyRdBKwKtlcBncH2J4Bn3f0ZAHd/w91PRX3dxVQhX2HTV03UeXL3be7+WrB/J9BqZmdF\nfd3FVOF3tYjUzfW4u78E7AE+HPV1F5OdL3d/291PBm+PAPI1el4I/N9gewPw6WDbgVFm1gy0Ar8D\nfl2FSy+oCvmqy3tGBPkq+Z4Ri6AB/CFw0N13A5jZu4AvAXcVSTfe3Q8E268D44PtCwE3s8fM7Gkz\nu60aFx1CpPkqIX01Rf27yvRp4Gl3Px7VxZYg6ny1Aa9kHPdqsG+oDcoXgJnNNrOdwA7ghoybUqad\npAIfwJ8B5wXb3wPeAg4A+4Gvu/uRal18AVHnqy7vGVBZvsq5Z9R8RLiZ/Rj4Tzneut3dHwm2ryXj\nCQ+4E/imu/9HKvAW5+5uZuko3Az8AfD7wNvARjPb6u4by8hCTjXKV8npS1GjPKU/ewbwD6Se+CJV\ny3xVU5n5wt23ADPM7D8Dq8zs/7j7b7PO8Rngf5rZ3wGPkipRQKq0dAqYCIwFfmpmP3b3FyPJFDXL\nV73eMyrN152Ues+oRZ1cifV3zcBBYFLGvp+SqivdBxwFjgB/nSPtLmBCRn3frmD7GmBVxnF/B9ya\ngHyFSh+nPAWvJwG/AOYm6DvYDXRnHPcY8JFa5yvHMU8AHUXOcyHws2D7W8BfZLz3L8DVCchXXd4z\nIshXyfeMIctwBf9RVwD/VuD9O8nfCHkPgxshvxZsjwWeJmhEAn4MLIh7vsKmj1OegDGkGoyvSth3\ncAaDG8JfZIgbVnPlK7iWdMPqe4HXgPfkSHtu8HMY8L+BzwSvvwR8O9geBTwHXJyAfNXlPaPSfIX9\nHmf+i0ObxjVkFccKMbP7zSw9YVcPMM/MdgMfD17j7m8C95LqUbCdVD35ukivurjI81UHqpGnvwYu\nAO7I6Fp4bpQXHUI1voM7gYdI3VR/BHzeh75hNVe+/gB4JujS+X3gv7n7L+GMfF1rZr8AXiB1o/p2\nsP9bwLuCOvZ/JxVAnq1yPrJFnq86vmdU+vsqmUaEi4hIaHEoaYiISJ1Q0BARkdAUNEREJDQFDRER\nCU1BQ0REQlPQEBGR0BQ0REQkNAUNEREJ7f8DynzTr6e9PPMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2389b0e410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(low['longitude'],low['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2389b3cf50>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njElhwcEYY0wKCw7GGGNS/H/dBhtR0gCUgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f237ff4b050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(med['longitude'],med['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f23823b9850>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23834aefd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(high['longitude'],high['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building_id', 'manager_id', 'display_address', 'building_id_medium', 'building_id_high', 'manager_id_medium', 'manager_id_high']\n",
      "['weekdays', 'manager_count', 'building_count', 'num_features', 'num_description_words', 'days', 'num_photos', 'created_month', 'created_day', 'created_hour']\n",
      "{'nTextFea': 300, 'step_size': 0.02, 'nQuantLevel': 10, 'category_nfold': 3}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-6c0889af6f02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#import pdb;pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
      "\u001b[0;32m<ipython-input-66-cf98af98fb49>\u001b[0m in \u001b[0;36mrunXGB_sklearn\u001b[0;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, num_rounds, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         clf.fit(train_X, train_y,eval_set=[(train_X, train_y), (test_X, test_y)],verbose=verbose,eval_metric='mlogloss',\n\u001b[0;32m---> 21\u001b[0;31m             early_stopping_rounds=50)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    443\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_scores = [] \n",
    "print fea_categorical\n",
    "print fea_additional\n",
    "print feature_params\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(train_X,train_y):\n",
    "    dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    preds, model = runXGB_sklearn(dev_X, dev_y, val_X, val_y,verbose=False)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
    "                                                                   model.best_score,log_loss(val_y, preds)))\n",
    "    importance_inx = np.argsort(model.feature_importances_*-1)\n",
    "    print('Most important 40 features:')\n",
    "    ff = [(fealist[x],model.feature_importances_[x]) for x in importance_inx[:40]]\n",
    "    print(ff)\n",
    "    print('-------------------------')\n",
    "          \n",
    "    #import pdb;pdb.set_trace()\n",
    "    cv_scores.append(log_loss(val_y, preds))\n",
    "    #print(cv_scores)\n",
    "    #break\n",
    "print 'mean score={}'.format(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building_id', 'manager_id', 'display_address', 'building_id_medium', 'building_id_high', 'manager_id_medium', 'manager_id_high']\n",
      "['weekdays', 'manager_count', 'building_count', 'num_features', 'num_description_words', 'days', 'num_photos', 'created_month', 'created_day', 'created_hour']\n",
      "best iterations:3333, best_score=0.52764, last_score=0.527691281573\n",
      "Most important 40 features:\n",
      "[('price', 0.057805404), ('manager_id_medium', 0.051225908), ('manager_id_high', 0.049443644), ('listing_id', 0.048090525), ('latitude', 0.045347061), ('building_id_medium', 0.044876315), ('longitude', 0.043825347), ('building_id_high', 0.041964259), ('num_description_words', 0.041846026), ('manager_id', 0.03915073), ('days', 0.038719397), ('display_address', 0.036470763), ('address_num', 0.035605904), ('manager_count', 0.035509568), ('building_id', 0.033547759), ('building_count', 0.026727419), ('created_day', 0.026427455), ('price_quantile_lat_long', 0.026175661), ('created_hour', 0.024353983), ('num_photos', 0.023020569), ('num_features', 0.020228935), ('price_quantile', 0.019276496), ('len_feature0', 0.018442292), ('bedrooms', 0.017710993), ('street_num', 0.017167993), ('weekdays', 0.014890896), ('bathrooms', 0.0095353406), ('lat_grid', 0.0092003448), ('no fee', 0.0085588172), ('ave_num', 0.0076085674), ('long_grid', 0.0075187972), ('furnished', 0.0042126281), ('laundry in building', 0.0040987735), ('west_east', 0.0036192695), ('hardwood floors', 0.0034046969), ('laundry in unit', 0.0031923139), ('dogs allowed', 0.003141955), ('created_month', 0.0029405197), ('dishwasher', 0.0029120559), ('cats allowed', 0.0027390842)]\n",
      "-------------------------\n",
      "best iterations:3207, best_score=0.518521, last_score=0.518548696838\n",
      "Most important 40 features:\n",
      "[('price', 0.057993039), ('manager_id_medium', 0.050171759), ('manager_id_high', 0.049814302), ('listing_id', 0.048791401), ('latitude', 0.046280228), ('longitude', 0.044333335), ('building_id_medium', 0.043865722), ('building_id_high', 0.042314507), ('num_description_words', 0.041783944), ('days', 0.038645539), ('manager_id', 0.038265605), ('display_address', 0.036804311), ('manager_count', 0.035286818), ('address_num', 0.035068747), ('building_id', 0.032870065), ('building_count', 0.027076608), ('price_quantile_lat_long', 0.026597753), ('created_day', 0.026231308), ('created_hour', 0.024028128), ('num_photos', 0.023663931), ('num_features', 0.020534517), ('price_quantile', 0.018873142), ('len_feature0', 0.018549409), ('bedrooms', 0.017926674), ('street_num', 0.017337661), ('weekdays', 0.01500634), ('bathrooms', 0.0096355313), ('lat_grid', 0.00939498), ('no fee', 0.0084192874), ('ave_num', 0.0080326069), ('long_grid', 0.007358165), ('laundry in building', 0.0040916163), ('furnished', 0.0040691346), ('west_east', 0.0037543951), ('laundry in unit', 0.0034171741), ('hardwood floors', 0.0033789556), ('pre-war', 0.0032867817), ('dogs allowed', 0.0032395709), ('created_month', 0.0028618833), ('dishwasher', 0.0028304092)]\n",
      "-------------------------\n",
      "best iterations:3529, best_score=0.522215, last_score=0.522219046073\n",
      "Most important 40 features:\n",
      "[('price', 0.056809377), ('manager_id_medium', 0.050821442), ('listing_id', 0.048552845), ('manager_id_high', 0.048386402), ('latitude', 0.045869164), ('building_id_medium', 0.044851996), ('longitude', 0.044258136), ('num_description_words', 0.042040914), ('building_id_high', 0.041952554), ('days', 0.039174348), ('manager_id', 0.038940091), ('display_address', 0.037033156), ('address_num', 0.036225587), ('manager_count', 0.034400847), ('building_id', 0.034300156), ('building_count', 0.027777949), ('created_day', 0.027494375), ('price_quantile_lat_long', 0.025799094), ('created_hour', 0.023653792), ('num_photos', 0.02289965), ('num_features', 0.020090621), ('len_feature0', 0.019280996), ('price_quantile', 0.018713847), ('bedrooms', 0.017877508), ('street_num', 0.017561056), ('weekdays', 0.015138345), ('lat_grid', 0.009333292), ('bathrooms', 0.0091236942), ('ave_num', 0.0085236672), ('no fee', 0.0080120005), ('long_grid', 0.0072064851), ('furnished', 0.0039720945), ('laundry in building', 0.0038303076), ('west_east', 0.0037008496), ('laundry in unit', 0.0033946717), ('hardwood floors', 0.0032960372), ('dogs allowed', 0.0031706891), ('pre-war', 0.0028953343), ('created_month', 0.0028583463), ('cats allowed', 0.002848072)]\n",
      "-------------------------\n",
      "best iterations:3364, best_score=0.525159, last_score=0.525184520279\n",
      "Most important 40 features:\n",
      "[('price', 0.056962229), ('manager_id_medium', 0.051253654), ('manager_id_high', 0.049892612), ('listing_id', 0.04932262), ('latitude', 0.045603596), ('building_id_medium', 0.044398595), ('longitude', 0.042751472), ('building_id_high', 0.042237833), ('num_description_words', 0.041836888), ('manager_id', 0.03900427), ('days', 0.038503632), ('display_address', 0.03614565), ('address_num', 0.035651512), ('manager_count', 0.035462961), ('building_id', 0.033815838), ('created_day', 0.026893593), ('building_count', 0.026709376), ('price_quantile_lat_long', 0.026080869), ('created_hour', 0.024082651), ('num_photos', 0.02335445), ('num_features', 0.020370126), ('price_quantile', 0.018959235), ('len_feature0', 0.018569129), ('bedrooms', 0.017806251), ('street_num', 0.017208086), ('weekdays', 0.014856603), ('lat_grid', 0.0096226577), ('bathrooms', 0.0092325499), ('no fee', 0.008411156), ('ave_num', 0.0083006257), ('long_grid', 0.0073188543), ('furnished', 0.0040462841), ('west_east', 0.003628002), ('laundry in unit', 0.0035976602), ('laundry in building', 0.0035911584), ('dogs allowed', 0.0033159158), ('hardwood floors', 0.0031620399), ('created_month', 0.0029821568), ('pre-war', 0.0029604842), ('cats allowed', 0.0029388117)]\n",
      "-------------------------\n",
      "best iterations:3104, best_score=0.528418, last_score=0.52847878788\n",
      "Most important 40 features:\n",
      "[('price', 0.057713609), ('manager_id_medium', 0.052152414), ('listing_id', 0.049353279), ('manager_id_high', 0.048818015), ('longitude', 0.046153277), ('latitude', 0.045432638), ('building_id_medium', 0.045015547), ('building_id_high', 0.042371664), ('num_description_words', 0.040059134), ('manager_id', 0.038103446), ('days', 0.037563547), ('display_address', 0.037032917), ('manager_count', 0.035533711), ('address_num', 0.034743559), ('building_id', 0.033401921), ('building_count', 0.02658019), ('price_quantile_lat_long', 0.026455063), ('created_day', 0.026072731), ('created_hour', 0.025361361), ('num_photos', 0.022974683), ('num_features', 0.020296041), ('price_quantile', 0.019149045), ('len_feature0', 0.018502556), ('bedrooms', 0.018062295), ('street_num', 0.01765679), ('weekdays', 0.014378004), ('lat_grid', 0.0098502645), ('bathrooms', 0.0097737983), ('no fee', 0.0088955928), ('ave_num', 0.0077578658), ('long_grid', 0.007227235), ('laundry in building', 0.0041036978), ('furnished', 0.0040967464), ('west_east', 0.0039994256), ('laundry in unit', 0.003401597), ('hardwood floors', 0.0032950074), ('dogs allowed', 0.0030285337), ('pre-war', 0.002894138), ('created_month', 0.0028501118), ('dishwasher', 0.0027945)]\n",
      "-------------------------\n",
      "mean score=0.524424466529\n"
     ]
    }
   ],
   "source": [
    "cv_scores = [] \n",
    "print fea_categorical\n",
    "print fea_additional\n",
    "print feature_params\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(train_X,train_y):\n",
    "    dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    preds, model = runXGB_sklearn(dev_X, dev_y, val_X, val_y,verbose=False)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
    "                                                                   model.best_score,log_loss(val_y, preds)))\n",
    "    importance_inx = np.argsort(model.feature_importances_*-1)\n",
    "    print('Most important 40 features:')\n",
    "    ff = [(fealist[x],model.feature_importances_[x]) for x in importance_inx[:40]]\n",
    "    print(ff)\n",
    "    print('-------------------------')\n",
    "          \n",
    "    #import pdb;pdb.set_trace()\n",
    "    cv_scores.append(log_loss(val_y, preds))\n",
    "    #print(cv_scores)\n",
    "    #break\n",
    "print 'mean score={}'.format(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-2132a394e2df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#import pdb;pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
      "\u001b[0;32m<ipython-input-66-cf98af98fb49>\u001b[0m in \u001b[0;36mrunXGB_sklearn\u001b[0;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, num_rounds, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         clf.fit(train_X, train_y,eval_set=[(train_X, train_y), (test_X, test_y)],verbose=verbose,eval_metric='mlogloss',\n\u001b[0;32m---> 21\u001b[0;31m             early_stopping_rounds=50)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    443\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jianqi/anaconda2/envs/xgboost/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_scores = [] \n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(train_X,train_y):\n",
    "    dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    preds, model = runXGB_sklearn(dev_X, dev_y, val_X, val_y,verbose=False)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    print('best iterations:{}, best_score={}, last_score={}'.format(model.best_iteration,\n",
    "                                                                   model.best_score,log_loss(val_y, preds)))\n",
    "    importance_inx = np.argsort(model.feature_importances_*-1)\n",
    "    print('Most important 40 features:')\n",
    "    ff = [(fealist[x],model.feature_importances_[x]) for x in importance_inx[:40]]\n",
    "    print(ff)\n",
    "    print('-------------------------')\n",
    "          \n",
    "    #import pdb;pdb.set_trace()\n",
    "    cv_scores.append(log_loss(val_y, preds))\n",
    "    #print(cv_scores)\n",
    "    #break\n",
    "print 'mean score={}'.format(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB_sklearn(train_X, train_y, test_X,num_rounds=4000)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "filename = time.asctime() +'_res.csv'\n",
    "out_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
